/root/miniconda3/lib/python3.8/site-packages/composer/callbacks/memory_monitor.py:86: UserWarning: The memory monitor only works on CUDA devices, but the model is on cpu.
  warnings.warn(f'The memory monitor only works on CUDA devices, but the model is on {model_device.type}.')
/root/miniconda3/lib/python3.8/site-packages/composer/callbacks/speed_monitor.py:120: UserWarning: gpu_flop count not found for None with precision: amp_bf16; MFU cannot be calculated and reported. gpu_flops_available can be manuallyoverridden by setting gpu_flops_available in SpeedMonitor.
  warnings.warn(
2025-04-04 11:42:41,684: rank0[4182][MainThread]: INFO: composer.trainer.trainer: Stepping schedulers every batch. To step schedulers every epoch, set `step_schedulers_every_batch=False`.
2025-04-04 11:42:41,685: rank0[4182][MainThread]: DEBUG: composer.trainer.trainer: Initializing deepspeed
Traceback (most recent call last):
  File "train.py", line 361, in <module>
    main(cfg)
  File "train.py", line 300, in main
    trainer = Trainer(
  File "/root/miniconda3/lib/python3.8/site-packages/composer/trainer/trainer.py", line 1280, in __init__
    (self.state.model, self.state.optimizers, _, _) = deepspeed.initialize(config=self.state.deepspeed_config,
  File "/root/miniconda3/lib/python3.8/site-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/root/miniconda3/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 259, in __init__
    self._configure_distributed_model(model)
  File "/root/miniconda3/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1090, in _configure_distributed_model
    self.module.to(self.device)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1145, in to
    return self._apply(convert)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 31.60 GiB total capacity; 989.58 MiB already allocated; 17.19 MiB free; 1.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-04-04 11:42:41,685] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown
[2025-04-04 11:42:41,686] [INFO] [comm.py:637:init_distributed] cdb=None
[31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mTraceback (most recent call last)[31m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
[31mâ”‚[39m /root/autodl-tmp/intrinsic-source-citation/[1mtrain.py[22m:[94m361[39m in [92m<module>[39m                              [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   358 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   359 â”‚   cli_cfg = om.from_cli(args_list)                                                       [31mâ”‚
[31mâ”‚[39m   360 â”‚   cfg = om.merge(yaml_cfg, cli_cfg)                                                      [31mâ”‚
[31mâ”‚[39m [31mâ± [39m361 â”‚   main(cfg)                                                                              [31mâ”‚
[31mâ”‚[39m   362                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/autodl-tmp/intrinsic-source-citation/[1mtrain.py[22m:[94m300[39m in [92mmain[39m                                  [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   297 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   298 â”‚   # Build the Trainer                                                                    [31mâ”‚
[31mâ”‚[39m   299 â”‚   [96mprint[39m([33m'Building trainer...'[39m)                                                           [31mâ”‚
[31mâ”‚[39m [31mâ± [39m300 â”‚   trainer = Trainer(                                                                     [31mâ”‚
[31mâ”‚[39m   301 â”‚   â”‚   run_name=cfg.run_name,                                                             [31mâ”‚
[31mâ”‚[39m   302 â”‚   â”‚   seed=cfg.seed,                                                                     [31mâ”‚
[31mâ”‚[39m   303 â”‚   â”‚   model=model,                                                                       [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/composer/trainer/[1mtrainer.py[22m:[94m1280[39m in [92m__init__[39m        [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1277 â”‚   â”‚   â”‚   [96mself[39m.state.deepspeed_config = _parse_deepspeed_config([96mself[39m.state.deepspeed_c  [31mâ”‚
[31mâ”‚[39m   1278 â”‚   â”‚   â”‚   optimizer = ensure_tuple([96mself[39m.state.optimizers)[[94m0[39m]                            [31mâ”‚
[31mâ”‚[39m   1279 â”‚   â”‚   â”‚   log.debug([33m'Initializing deepspeed'[39m)                                           [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1280 â”‚   â”‚   â”‚   ([96mself[39m.state.model, [96mself[39m.state.optimizers, _, _) = deepspeed.initialize(confi  [31mâ”‚
[31mâ”‚[39m   1281 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      model  [31mâ”‚
[31mâ”‚[39m   1282 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      optim  [31mâ”‚
[31mâ”‚[39m   1283 â”‚   â”‚   â”‚   # Since the DeepSpeed ZeRO optimizer does not inherit torch.optim.Optimizer,  [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/deepspeed/[1m__init__.py[22m:[94m171[39m in [92minitialize[39m             [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   168 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      config=config,                                  [31mâ”‚
[31mâ”‚[39m   169 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      config_class=config_class)                      [31mâ”‚
[31mâ”‚[39m   170 â”‚   â”‚   [94melse[39m:                                                                              [31mâ”‚
[31mâ”‚[39m [31mâ± [39m171 â”‚   â”‚   â”‚   engine = DeepSpeedEngine(args=args,                                            [31mâ”‚
[31mâ”‚[39m   172 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚    model=model,                                          [31mâ”‚
[31mâ”‚[39m   173 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚    optimizer=optimizer,                                  [31mâ”‚
[31mâ”‚[39m   174 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚    model_parameters=model_parameters,                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/deepspeed/runtime/[1mengine.py[22m:[94m259[39m in [92m__init__[39m         [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    256 â”‚   â”‚   [96mself[39m.pipeline_parallelism = [96misinstance[39m(model, PipelineModule)                     [31mâ”‚
[31mâ”‚[39m    257 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m    258 â”‚   â”‚   # Configure distributed model                                                     [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 259 â”‚   â”‚   [96mself[39m._configure_distributed_model(model)                                          [31mâ”‚
[31mâ”‚[39m    260 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m    261 â”‚   â”‚   # needed for zero_to_fp32 weights reconstruction to remap nameless data to state  [31mâ”‚
[31mâ”‚[39m    262 â”‚   â”‚   [96mself[39m.param_names = {param: name [94mfor[39m name, param [95min[39m model.named_parameters()}      [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/deepspeed/runtime/[1mengine.py[22m:[94m1090[39m in                 [31mâ”‚
[31mâ”‚[39m [92m_configure_distributed_model[39m                                                                     [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1087 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m   1088 â”‚   â”‚   # zero.Init() handles device placement of model                                   [31mâ”‚
[31mâ”‚[39m   1089 â”‚   â”‚   [94mif[39m [95mnot[39m ([96mself[39m.dont_change_device [95mor[39m is_zero_init_model):                           [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1090 â”‚   â”‚   â”‚   [96mself[39m.module.to([96mself[39m.device)                                                   [31mâ”‚
[31mâ”‚[39m   1091 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m   1092 â”‚   â”‚   # MoE related initialization                                                      [31mâ”‚
[31mâ”‚[39m   1093 â”‚   â”‚   [94mfor[39m _, module [95min[39m [96mself[39m.module.named_modules():                                     [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m1145[39m in [92mto[39m               [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1142 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   non_blocking, memory_format=convert_to_format)                [31mâ”‚
[31mâ”‚[39m   1143 â”‚   â”‚   â”‚   [94mreturn[39m t.to(device, dtype [94mif[39m t.is_floating_point() [95mor[39m t.is_complex() [94melse[39m [94mNo[39m  [31mâ”‚
[31mâ”‚[39m   1144 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1145 â”‚   â”‚   [94mreturn[39m [96mself[39m._apply(convert)                                                       [31mâ”‚
[31mâ”‚[39m   1146 â”‚                                                                                         [31mâ”‚
[31mâ”‚[39m   1147 â”‚   [94mdef[39m [92mregister_full_backward_pre_hook[39m(                                                  [31mâ”‚
[31mâ”‚[39m   1148 â”‚   â”‚   [96mself[39m,                                                                             [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m797[39m in [92m_apply[39m            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    794 â”‚                                                                                         [31mâ”‚
[31mâ”‚[39m    795 â”‚   [94mdef[39m [92m_apply[39m([96mself[39m, fn):                                                                 [31mâ”‚
[31mâ”‚[39m    796 â”‚   â”‚   [94mfor[39m module [95min[39m [96mself[39m.children():                                                    [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 797 â”‚   â”‚   â”‚   module._apply(fn)                                                             [31mâ”‚
[31mâ”‚[39m    798 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m    799 â”‚   â”‚   [94mdef[39m [92mcompute_should_use_set_data[39m(tensor, tensor_applied):                          [31mâ”‚
[31mâ”‚[39m    800 â”‚   â”‚   â”‚   [94mif[39m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m797[39m in [92m_apply[39m            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    794 â”‚                                                                                         [31mâ”‚
[31mâ”‚[39m    795 â”‚   [94mdef[39m [92m_apply[39m([96mself[39m, fn):                                                                 [31mâ”‚
[31mâ”‚[39m    796 â”‚   â”‚   [94mfor[39m module [95min[39m [96mself[39m.children():                                                    [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 797 â”‚   â”‚   â”‚   module._apply(fn)                                                             [31mâ”‚
[31mâ”‚[39m    798 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m    799 â”‚   â”‚   [94mdef[39m [92mcompute_should_use_set_data[39m(tensor, tensor_applied):                          [31mâ”‚
[31mâ”‚[39m    800 â”‚   â”‚   â”‚   [94mif[39m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m797[39m in [92m_apply[39m            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    794 â”‚                                                                                         [31mâ”‚
[31mâ”‚[39m    795 â”‚   [94mdef[39m [92m_apply[39m([96mself[39m, fn):                                                                 [31mâ”‚
[31mâ”‚[39m    796 â”‚   â”‚   [94mfor[39m module [95min[39m [96mself[39m.children():                                                    [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 797 â”‚   â”‚   â”‚   module._apply(fn)                                                             [31mâ”‚
[31mâ”‚[39m    798 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m    799 â”‚   â”‚   [94mdef[39m [92mcompute_should_use_set_data[39m(tensor, tensor_applied):                          [31mâ”‚
[31mâ”‚[39m    800 â”‚   â”‚   â”‚   [94mif[39m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m797[39m in [92m_apply[39m            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    794 â”‚                                                                                         [31mâ”‚
[31mâ”‚[39m    795 â”‚   [94mdef[39m [92m_apply[39m([96mself[39m, fn):                                                                 [31mâ”‚
[31mâ”‚[39m    796 â”‚   â”‚   [94mfor[39m module [95min[39m [96mself[39m.children():                                                    [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 797 â”‚   â”‚   â”‚   module._apply(fn)                                                             [31mâ”‚
[31mâ”‚[39m    798 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m    799 â”‚   â”‚   [94mdef[39m [92mcompute_should_use_set_data[39m(tensor, tensor_applied):                          [31mâ”‚
[31mâ”‚[39m    800 â”‚   â”‚   â”‚   [94mif[39m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m797[39m in [92m_apply[39m            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    794 â”‚                                                                                         [31mâ”‚
[31mâ”‚[39m    795 â”‚   [94mdef[39m [92m_apply[39m([96mself[39m, fn):                                                                 [31mâ”‚
[31mâ”‚[39m    796 â”‚   â”‚   [94mfor[39m module [95min[39m [96mself[39m.children():                                                    [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 797 â”‚   â”‚   â”‚   module._apply(fn)                                                             [31mâ”‚
[31mâ”‚[39m    798 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m    799 â”‚   â”‚   [94mdef[39m [92mcompute_should_use_set_data[39m(tensor, tensor_applied):                          [31mâ”‚
[31mâ”‚[39m    800 â”‚   â”‚   â”‚   [94mif[39m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m797[39m in [92m_apply[39m            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    794 â”‚                                                                                         [31mâ”‚
[31mâ”‚[39m    795 â”‚   [94mdef[39m [92m_apply[39m([96mself[39m, fn):                                                                 [31mâ”‚
[31mâ”‚[39m    796 â”‚   â”‚   [94mfor[39m module [95min[39m [96mself[39m.children():                                                    [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 797 â”‚   â”‚   â”‚   module._apply(fn)                                                             [31mâ”‚
[31mâ”‚[39m    798 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m    799 â”‚   â”‚   [94mdef[39m [92mcompute_should_use_set_data[39m(tensor, tensor_applied):                          [31mâ”‚
[31mâ”‚[39m    800 â”‚   â”‚   â”‚   [94mif[39m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m820[39m in [92m_apply[39m            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    817 â”‚   â”‚   â”‚   # track autograd history of `param_applied`, so we have to use                [31mâ”‚
[31mâ”‚[39m    818 â”‚   â”‚   â”‚   # `with torch.no_grad():`                                                     [31mâ”‚
[31mâ”‚[39m    819 â”‚   â”‚   â”‚   [94mwith[39m torch.no_grad():                                                         [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 820 â”‚   â”‚   â”‚   â”‚   param_applied = fn(param)                                                 [31mâ”‚
[31mâ”‚[39m    821 â”‚   â”‚   â”‚   should_use_set_data = compute_should_use_set_data(param, param_applied)       [31mâ”‚
[31mâ”‚[39m    822 â”‚   â”‚   â”‚   [94mif[39m should_use_set_data:                                                       [31mâ”‚
[31mâ”‚[39m    823 â”‚   â”‚   â”‚   â”‚   param.data = param_applied                                                [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m1143[39m in [92mconvert[39m          [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1140 â”‚   â”‚   â”‚   [94mif[39m convert_to_format [95mis[39m [95mnot[39m [94mNone[39m [95mand[39m t.dim() [95min[39m ([94m4[39m, [94m5[39m):                       [31mâ”‚
[31mâ”‚[39m   1141 â”‚   â”‚   â”‚   â”‚   [94mreturn[39m t.to(device, dtype [94mif[39m t.is_floating_point() [95mor[39m t.is_complex() [94mels[39m  [31mâ”‚
[31mâ”‚[39m   1142 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   non_blocking, memory_format=convert_to_format)                [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1143 â”‚   â”‚   â”‚   [94mreturn[39m t.to(device, dtype [94mif[39m t.is_floating_point() [95mor[39m t.is_complex() [94melse[39m [94mNo[39m  [31mâ”‚
[31mâ”‚[39m   1144 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m   1145 â”‚   â”‚   [94mreturn[39m [96mself[39m._apply(convert)                                                       [31mâ”‚
[31mâ”‚[39m   1146                                                                                           [31mâ”‚
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[1mOutOfMemoryError: [22mCUDA out of memory. Tried to allocate [1m22.00[22m MiB [1m([22mGPU [1m0[22m; [1m31.60[22m GiB total capacity; [1m989.58[22m MiB already
allocated; [1m17.19[22m MiB free; [1m1.01[22m GiB reserved in total by PyTorch[1m)[22m If reserved memory is >> allocated memory try setting
max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF