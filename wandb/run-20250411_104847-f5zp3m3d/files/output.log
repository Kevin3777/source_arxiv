/root/miniconda3/lib/python3.8/site-packages/composer/callbacks/memory_monitor.py:86: UserWarning: The memory monitor only works on CUDA devices, but the model is on cpu.
  warnings.warn(f'The memory monitor only works on CUDA devices, but the model is on {model_device.type}.')
/root/miniconda3/lib/python3.8/site-packages/composer/callbacks/speed_monitor.py:120: UserWarning: gpu_flop count not found for None with precision: amp_bf16; MFU cannot be calculated and reported. gpu_flops_available can be manuallyoverridden by setting gpu_flops_available in SpeedMonitor.
  warnings.warn(
2025-04-11 10:49:08,083: rank0[3554][MainThread]: INFO: composer.trainer.trainer: Stepping schedulers every batch. To step schedulers every epoch, set `step_schedulers_every_batch=False`.
2025-04-11 10:49:08,084: rank0[3554][MainThread]: DEBUG: composer.trainer.trainer: Initializing deepspeed
[2025-04-11 10:49:08,084] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown
[2025-04-11 10:49:08,084] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-04-11 10:49:09,379] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-04-11 10:49:09,381] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-04-11 10:49:09,381] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-04-11 10:49:09,398] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2025-04-11 10:49:09,398] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2025-04-11 10:49:09,398] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2025-04-11 10:49:09,399] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2025-04-11 10:49:09,639] [INFO] [utils.py:791:see_memory_usage] Stage 3 initialize beginning
[2025-04-11 10:49:09,641] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.15 GB         Max_CA 2 GB
[2025-04-11 10:49:09,641] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 135.69 GB, percent = 13.5%
[2025-04-11 10:49:09,643] [INFO] [stage3.py:127:__init__] Reduce bucket size 1
[2025-04-11 10:49:09,644] [INFO] [stage3.py:128:__init__] Prefetch bucket size 50,000,000
[2025-04-11 10:49:09,845] [INFO] [utils.py:791:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-04-11 10:49:09,846] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.15 GB         Max_CA 2 GB
[2025-04-11 10:49:09,847] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 135.27 GB, percent = 13.4%
Parameter Offload: Total persistent parameters: 92160 in 45 params
[2025-04-11 10:49:10,139] [INFO] [utils.py:791:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-04-11 10:49:10,141] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.18 GB         CA 2.31 GB         Max_CA 2 GB
[2025-04-11 10:49:10,141] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 135.07 GB, percent = 13.4%
[2025-04-11 10:49:10,349] [INFO] [utils.py:791:see_memory_usage] Before creating fp16 partitions
[2025-04-11 10:49:10,351] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.31 GB         Max_CA 2 GB
[2025-04-11 10:49:10,351] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 135.69 GB, percent = 13.5%
[2025-04-11 10:49:12,758] [INFO] [utils.py:791:see_memory_usage] After creating fp16 partitions: 2
[2025-04-11 10:49:12,761] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB
[2025-04-11 10:49:12,762] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 135.15 GB, percent = 13.4%
[2025-04-11 10:49:12,964] [INFO] [utils.py:791:see_memory_usage] Before creating fp32 partitions
[2025-04-11 10:49:12,966] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB
[2025-04-11 10:49:12,966] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 134.39 GB, percent = 13.3%
[2025-04-11 10:49:15,469] [INFO] [utils.py:791:see_memory_usage] After creating fp32 partitions
[2025-04-11 10:49:15,471] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB
[2025-04-11 10:49:15,472] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 138.67 GB, percent = 13.8%
[2025-04-11 10:49:15,671] [INFO] [utils.py:791:see_memory_usage] Before initializing optimizer states
[2025-04-11 10:49:15,672] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB
[2025-04-11 10:49:15,673] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 138.4 GB, percent = 13.7%
[2025-04-11 10:49:52,924] [INFO] [utils.py:791:see_memory_usage] After initializing optimizer states
[2025-04-11 10:49:52,926] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.06 GB         CA 2.07 GB         Max_CA 2 GB
[2025-04-11 10:49:52,926] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 151.31 GB, percent = 15.0%
[2025-04-11 10:49:52,926] [INFO] [stage3.py:479:_setup_for_real_optimizer] optimizer state initialized
2025-04-11 10:49:55,588: rank0[3554][MainThread]: INFO: composer.trainer.trainer: Setting seed to 17
2025-04-11 10:49:55,588: rank0[3554][MainThread]: INFO: composer.utils.reproducibility: Setting seed to 17
2025-04-11 10:49:55,615: rank0[3554][MainThread]: INFO: composer.trainer.trainer: Using precision Precision.AMP_BF16
******************************
Config:
enabled_algorithms/GradientClipping: true
node_name: unknown because NODENAME environment variable not set
num_gpus_per_node: 1
num_nodes: 1
rank_zero_seed: 17
******************************
2025-04-11 10:49:55,617: rank0[3554][MainThread]: DEBUG: composer.trainer.trainer: Spinning the dataloaders
[2025-04-11 10:49:55,573] [INFO] [utils.py:791:see_memory_usage] After initializing ZeRO optimizer
[2025-04-11 10:49:55,575] [INFO] [utils.py:792:see_memory_usage] MA 2.06 GB         Max_MA 2.31 GB         CA 2.38 GB         Max_CA 2 GB
[2025-04-11 10:49:55,575] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 156.96 GB, percent = 15.6%
[2025-04-11 10:49:55,575] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2025-04-11 10:49:55,576] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-04-11 10:49:55,576] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-04-11 10:49:55,576] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[[0.9, 0.98]]
[2025-04-11 10:49:55,577] [INFO] [config.py:984:print] DeepSpeedEngine configuration:
[2025-04-11 10:49:55,578] [INFO] [config.py:988:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2025-04-11 10:49:55,578] [INFO] [config.py:988:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-04-11 10:49:55,578] [INFO] [config.py:988:print]   amp_enabled .................. False
[2025-04-11 10:49:55,578] [INFO] [config.py:988:print]   amp_params ................... False
[2025-04-11 10:49:55,579] [INFO] [config.py:988:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2025-04-11 10:49:55,579] [INFO] [config.py:988:print]   bfloat16_enabled ............. True
[2025-04-11 10:49:55,579] [INFO] [config.py:988:print]   checkpoint_parallel_write_pipeline  False
[2025-04-11 10:49:55,579] [INFO] [config.py:988:print]   checkpoint_tag_validation_enabled  True
[2025-04-11 10:49:55,579] [INFO] [config.py:988:print]   checkpoint_tag_validation_fail  False
[2025-04-11 10:49:55,579] [INFO] [config.py:988:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7c3818c6a0>
[2025-04-11 10:49:55,579] [INFO] [config.py:988:print]   communication_data_type ...... None
[2025-04-11 10:49:55,580] [INFO] [config.py:988:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-04-11 10:49:55,580] [INFO] [config.py:988:print]   curriculum_enabled_legacy .... False
[2025-04-11 10:49:55,580] [INFO] [config.py:988:print]   curriculum_params_legacy ..... False
[2025-04-11 10:49:55,580] [INFO] [config.py:988:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-04-11 10:49:55,580] [INFO] [config.py:988:print]   data_efficiency_enabled ...... False
[2025-04-11 10:49:55,580] [INFO] [config.py:988:print]   dataloader_drop_last ......... False
[2025-04-11 10:49:55,580] [INFO] [config.py:988:print]   disable_allgather ............ False
[2025-04-11 10:49:55,580] [INFO] [config.py:988:print]   dump_state ................... False
[2025-04-11 10:49:55,580] [INFO] [config.py:988:print]   dynamic_loss_scale_args ...... None
[2025-04-11 10:49:55,581] [INFO] [config.py:988:print]   eigenvalue_enabled ........... False
[2025-04-11 10:49:55,581] [INFO] [config.py:988:print]   eigenvalue_gas_boundary_resolution  1
[2025-04-11 10:49:55,581] [INFO] [config.py:988:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-04-11 10:49:55,581] [INFO] [config.py:988:print]   eigenvalue_layer_num ......... 0
[2025-04-11 10:49:55,581] [INFO] [config.py:988:print]   eigenvalue_max_iter .......... 100
[2025-04-11 10:49:55,581] [INFO] [config.py:988:print]   eigenvalue_stability ......... 1e-06
[2025-04-11 10:49:55,581] [INFO] [config.py:988:print]   eigenvalue_tol ............... 0.01
[2025-04-11 10:49:55,581] [INFO] [config.py:988:print]   eigenvalue_verbose ........... False
[2025-04-11 10:49:55,581] [INFO] [config.py:988:print]   elasticity_enabled ........... False
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   fp16_auto_cast ............... None
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   fp16_enabled ................. False
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   fp16_master_weights_and_gradients  False
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   global_rank .................. 0
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   grad_accum_dtype ............. None
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   gradient_accumulation_steps .. 32
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   gradient_clipping ............ 1.0
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   gradient_predivide_factor .... 1.0
[2025-04-11 10:49:55,582] [INFO] [config.py:988:print]   graph_harvesting ............. False
[2025-04-11 10:49:55,583] [INFO] [config.py:988:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-04-11 10:49:55,583] [INFO] [config.py:988:print]   initial_dynamic_scale ........ 1
[2025-04-11 10:49:55,583] [INFO] [config.py:988:print]   load_universal_checkpoint .... False
[2025-04-11 10:49:55,583] [INFO] [config.py:988:print]   loss_scale ................... 1.0
[2025-04-11 10:49:55,583] [INFO] [config.py:988:print]   memory_breakdown ............. False
[2025-04-11 10:49:55,583] [INFO] [config.py:988:print]   mics_hierarchial_params_gather  False
[2025-04-11 10:49:55,583] [INFO] [config.py:988:print]   mics_shard_size .............. -1
[2025-04-11 10:49:55,583] [INFO] [config.py:988:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   optimizer_legacy_fusion ...... False
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   optimizer_name ............... None
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   optimizer_params ............. None
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   pld_enabled .................. False
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   pld_params ................... False
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   prescale_gradients ........... False
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   scheduler_name ............... None
[2025-04-11 10:49:55,584] [INFO] [config.py:988:print]   scheduler_params ............. None
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   seq_parallel_communication_data_type  torch.float32
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   sparse_attention ............. None
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   sparse_gradients_enabled ..... False
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   steps_per_print .............. 10
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   train_batch_size ............. 64
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   train_micro_batch_size_per_gpu  2
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   use_data_before_expert_parallel_  False
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   use_node_local_storage ....... False
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   wall_clock_breakdown ......... False
[2025-04-11 10:49:55,585] [INFO] [config.py:988:print]   weight_quantization_config ... None
[2025-04-11 10:49:55,586] [INFO] [config.py:988:print]   world_size ................... 1
[2025-04-11 10:49:55,586] [INFO] [config.py:988:print]   zero_allow_untested_optimizer  True
[2025-04-11 10:49:55,586] [INFO] [config.py:988:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-04-11 10:49:55,586] [INFO] [config.py:988:print]   zero_enabled ................. True
[2025-04-11 10:49:55,586] [INFO] [config.py:988:print]   zero_force_ds_cpu_optimizer .. True
[2025-04-11 10:49:55,586] [INFO] [config.py:988:print]   zero_optimization_stage ...... 3
[2025-04-11 10:49:55,586] [INFO] [config.py:974:print_user_config]   json = {
    "bf16": {
        "enabled": true
    },
    "train_batch_size": 64,
    "zero_optimization": {
        "allgather_bucket_size": 2.000000e+08,
        "contiguous_gradients": true,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "reduce_bucket_size": true,
        "reduce_scatter": true,
        "stage": 3
    },
    "gradient_clipping": 1.0,
    "gradient_accumulation_steps": 32,
    "train_micro_batch_size_per_gpu": 2,
    "zero_allow_untested_optimizer": true
}
Logging config...
algorithms:
  gradient_clipping:
    clipping_threshold: 1.0
    clipping_type: norm
callbacks:
  lr_monitor: {}
  memory_monitor: {}
  runtime_estimator: {}
  speed_monitor:
    window_size: 10
console_log_interval: 50ba
cross_doc_attention: false
dataloaders:
- dataset:
    batch_type: lm
    local: outputs/experiments/seq-training-doc-id-begin/data/streaming/
    max_seq_len: 2048
    shuffle: true
    split: train
  drop_last: false
  name: train_loader_docs
  num_workers: 0
- dataset:
    max_seq_len: 2048
    path: dataset/BioCite/qa
    split: qa_eval_in_domain
  drop_last: false
  name: in_domain_standard_q_answer_eval_loader
  num_workers: 0
- dataset:
    max_seq_len: 2048
    path: dataset/BioCite/qa
    split: qa_eval_out_of_domain
  drop_last: false
  name: out_of_domain_standard_q_answer_eval_loader
  num_workers: 0
- dataset:
    batch_type: fact
    local: outputs/experiments/seq-training-doc-id-begin/data/streaming/qa
    masking:
      cross_doc_attention: false
    max_seq_len: 2048
    shuffle: true
    split: qa_attribution_train
  drop_last: false
  name: train_q_a_url
  num_workers: 0
deepspeed_config:
  bf16:
    enabled: true
  train_batch_size: 64
  zero_optimization:
    allgather_bucket_size: 200000000.0
    contiguous_gradients: true
    offload_optimizer:
      device: cpu
      pin_memory: true
    overlap_comm: true
    reduce_bucket_size: true
    reduce_scatter: true
    stage: 3
device_eval_batch_size: 40
device_train_microbatch_size: 2
eval_first: false
eval_interval: 1ep
eval_subset_num_batches: -1
experiment:
  data:
    augment:
      doc:
        do: false
        method: permute
        n_sample_per_doc: 2
    finetune:
      neg_create_probability: 0.0
      number_non_attributable_negatives: 0
    text_data_path: dataset/BioCite
  eval:
    disable_all_eval: false
    disable_attribution_eval: false
    disable_non_attrib_eval: true
    disable_qa_eval: false
    icl_eval: false
    ppl_eval: false
    use_ais: false
  experiment:
    name: seq-training-doc-id-begin
    output_dir: outputs/experiments/
  model:
    name: TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T
  train:
    config_template_path: conf/templates/train_config.yaml
    cross_doc_attention: false
    device_eval_batch_size: 40
    device_train_microbatch_size: 2
    eval_first: false
    finetune_q_a: false
    finetune_q_a_doc_url: false
    finetune_q_a_url: true
    finetune_q_url_a: false
    loss_type: mask
    lr: 8.0e-05
    max_duration: 10ep
    pretrain: true
    q_a_url_predict_url_only: false
    repeat_url_across_doc: false
    save_folder: null
    sequential: false
    url_location: first
    url_loss_factor: 1.0
    weight_decay: 0.02
global_seed: 17
global_train_batch_size: 64
log_to_console: true
loggers:
  wandb:
    project: intrinsic-source-citation
max_duration: 10ep
max_seq_len: 2048
model:
  checkpoint: null
  loss:
    type: mask
    url_loss_factor: 1.0
  name: hf_causal_lm
  pretrained: true
  pretrained_model_name_or_path: TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T
ood_url_trie: outputs/experiments/seq-training-doc-id-begin/data/streaming/unseen_url_trie.pkl
optimizer:
  betas:
  - 0.9
  - 0.98
  eps: 1.0e-06
  lr: 8.0e-05
  name: deepspeed_adam
  weight_decay: 0.02
precision: amp_bf16
progress_bar: false
run_name: seq-training-doc-id-begin
save_folder: null
save_interval: 1ep
save_num_checkpoints_to_keep: 1
scheduler:
  alpha_f: 0.1
  name: linear_decay_with_warmup
  t_warmup: 1ep
seed: 17
streaming: outputs/experiments/seq-training-doc-id-begin/data/streaming/
text_data_path: dataset/BioCite
tokenizer:
  kwargs:
    model_max_length: 2048
  name: outputs/experiments/seq-training-doc-id-begin/data/streaming//tokenizer
tokenizer_name: outputs/experiments/seq-training-doc-id-begin/data/streaming//tokenizer
url_trie: outputs/experiments/seq-training-doc-id-begin/data/streaming/url_trie.pkl
dist_timeout: 600.0
n_gpus: 1
device_train_batch_size: 64
device_train_grad_accum: 32
n_params: 1100056576
Starting training...
[epoch=1][batch=1/402]:
	 Train time/epoch: 0
	 Train time/batch: 0
	 Train time/sample: 0
	 Train time/batch_in_epoch: 0
	 Train time/sample_in_epoch: 0
	 Train time/token: 0
	 Train time/token_in_epoch: 0
	 Train memory/allocated_mem: 3.3432
	 Train memory/active_mem: 3.3432
	 Train memory/inactive_mem: 0.0542
	 Train memory/reserved_mem: 21.2820
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 5.5417
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/train: 0.0084
	 Train time/val: 0.0000
	 Train time/total: 0.0084
[2025-04-11 10:54:49,469] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.592039800995025e-06], mom=[[0.9, 0.98]]
[2025-04-11 10:54:49,470] [INFO] [timer.py:260:stop] epoch=0/micro_step=320/global_step=10, RunningAvgSamplesPerSec=2.3036664586013607, CurrSamplesPerSec=2.308690968467189, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 10:59:37,766] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[3.582089552238806e-06], mom=[[0.9, 0.98]]
[2025-04-11 10:59:37,768] [INFO] [timer.py:260:stop] epoch=0/micro_step=640/global_step=20, RunningAvgSamplesPerSec=2.3208425947856184, CurrSamplesPerSec=2.3101093391950496, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:04:26,007] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[5.572139303482588e-06], mom=[[0.9, 0.98]]
[2025-04-11 11:04:26,008] [INFO] [timer.py:260:stop] epoch=0/micro_step=960/global_step=30, RunningAvgSamplesPerSec=2.3259278569608903, CurrSamplesPerSec=2.34036795646542, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:09:11,885] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[7.5621890547263685e-06], mom=[[0.9, 0.98]]
[2025-04-11 11:09:11,886] [INFO] [timer.py:260:stop] epoch=0/micro_step=1280/global_step=40, RunningAvgSamplesPerSec=2.333118333986429, CurrSamplesPerSec=2.3035624822680654, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[epoch=1][batch=50/402]:
	 Train time/batch: 49
	 Train time/sample: 3136
	 Train time/batch_in_epoch: 49
	 Train time/sample_in_epoch: 3136
	 Train time/token: 3201920
	 Train time/token_in_epoch: 3201920
	 Train memory/allocated_mem: 3.3429
	 Train memory/active_mem: 3.3429
	 Train memory/inactive_mem: 0.0440
	 Train memory/reserved_mem: 21.2840
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.3673
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 31.5865
	 Train time/train: 0.3986
	 Train time/val: 0.0000
	 Train time/total: 0.3986
	 Train throughput/batches_per_sec: 0.0359
	 Train throughput/samples_per_sec: 2.2960
	 Train throughput/device/batches_per_sec: 0.0359
	 Train throughput/device/samples_per_sec: 2.2960
[2025-04-11 11:13:50,627] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[9.552238805970149e-06], mom=[[0.9, 0.98]]
[2025-04-11 11:13:50,629] [INFO] [timer.py:260:stop] epoch=0/micro_step=1600/global_step=50, RunningAvgSamplesPerSec=2.3495783196001545, CurrSamplesPerSec=2.5393505823530234, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:18:20,719] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[1.1542288557213931e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:18:20,720] [INFO] [timer.py:260:stop] epoch=0/micro_step=1920/global_step=60, RunningAvgSamplesPerSec=2.373246953278292, CurrSamplesPerSec=2.3095877951826247, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:23:02,090] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[1.3532338308457713e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:23:02,091] [INFO] [timer.py:260:stop] epoch=0/micro_step=2240/global_step=70, RunningAvgSamplesPerSec=2.375052579848818, CurrSamplesPerSec=2.3546116587652426, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:27:41,529] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[1.5522388059701494e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:27:41,530] [INFO] [timer.py:260:stop] epoch=0/micro_step=2560/global_step=80, RunningAvgSamplesPerSec=2.3783614628945253, CurrSamplesPerSec=2.371578963289697, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:32:16,422] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[1.7512437810945274e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:32:16,423] [INFO] [timer.py:260:stop] epoch=0/micro_step=2880/global_step=90, RunningAvgSamplesPerSec=2.38563196222065, CurrSamplesPerSec=2.4102611124489703, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[epoch=1][batch=100/402]:
	 Train time/batch: 99
	 Train time/sample: 6336
	 Train time/batch_in_epoch: 99
	 Train time/sample_in_epoch: 6336
	 Train time/token: 6467840
	 Train time/token_in_epoch: 6467840
	 Train memory/allocated_mem: 3.3429
	 Train memory/active_mem: 3.3429
	 Train memory/inactive_mem: 0.0356
	 Train memory/reserved_mem: 21.2840
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2572
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 30.6463
	 Train throughput/batches_per_sec: 0.0361
	 Train throughput/samples_per_sec: 2.3103
	 Train throughput/device/batches_per_sec: 0.0361
	 Train throughput/device/samples_per_sec: 2.3103
	 Train time/train: 0.7827
	 Train time/val: 0.0000
	 Train time/total: 0.7827
[2025-04-11 11:36:53,449] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[1.9502487562189055e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:36:53,450] [INFO] [timer.py:260:stop] epoch=0/micro_step=3200/global_step=100, RunningAvgSamplesPerSec=2.3899511697021274, CurrSamplesPerSec=2.40684568567401, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:41:33,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[2.149253731343284e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:41:33,428] [INFO] [timer.py:260:stop] epoch=0/micro_step=3520/global_step=110, RunningAvgSamplesPerSec=2.390851662871425, CurrSamplesPerSec=2.4032718068086996, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:46:09,691] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[2.348258706467662e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:46:09,692] [INFO] [timer.py:260:stop] epoch=0/micro_step=3840/global_step=120, RunningAvgSamplesPerSec=2.394193462515317, CurrSamplesPerSec=2.5415726914734256, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:50:45,421] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[2.54726368159204e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:50:45,422] [INFO] [timer.py:260:stop] epoch=0/micro_step=4160/global_step=130, RunningAvgSamplesPerSec=2.3974359402094976, CurrSamplesPerSec=2.4862376442368035, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 11:55:22,587] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[2.746268656716418e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:55:22,588] [INFO] [timer.py:260:stop] epoch=0/micro_step=4480/global_step=140, RunningAvgSamplesPerSec=2.399086431732875, CurrSamplesPerSec=2.5662747416461653, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[epoch=1][batch=150/402]:
	 Train time/batch: 149
	 Train time/sample: 9536
	 Train time/batch_in_epoch: 149
	 Train time/sample_in_epoch: 9536
	 Train time/token: 9730240
	 Train time/token_in_epoch: 9730240
	 Train memory/allocated_mem: 3.3431
	 Train memory/active_mem: 3.3431
	 Train memory/inactive_mem: 0.0417
	 Train memory/reserved_mem: 21.2840
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2404
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 30.0690
	 Train throughput/batches_per_sec: 0.0367
	 Train throughput/samples_per_sec: 2.3507
	 Train throughput/device/batches_per_sec: 0.0367
	 Train throughput/device/samples_per_sec: 2.3507
	 Train time/train: 1.1664
	 Train time/val: 0.0000
	 Train time/total: 1.1664
[2025-04-11 11:59:54,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[2.945273631840796e-05], mom=[[0.9, 0.98]]
[2025-04-11 11:59:54,843] [INFO] [timer.py:260:stop] epoch=0/micro_step=4800/global_step=150, RunningAvgSamplesPerSec=2.403389584644171, CurrSamplesPerSec=2.403511177039959, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:04:26,773] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[3.144278606965174e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:04:26,774] [INFO] [timer.py:260:stop] epoch=0/micro_step=5120/global_step=160, RunningAvgSamplesPerSec=2.408235569915399, CurrSamplesPerSec=2.605321152807545, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:08:56,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=0, lr=[3.343283582089552e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:08:56,017] [INFO] [timer.py:260:stop] epoch=0/micro_step=5440/global_step=170, RunningAvgSamplesPerSec=2.4138424533541714, CurrSamplesPerSec=2.4798415786382217, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:13:26,617] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=0, lr=[3.54228855721393e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:13:26,617] [INFO] [timer.py:260:stop] epoch=0/micro_step=5760/global_step=180, RunningAvgSamplesPerSec=2.418416979917572, CurrSamplesPerSec=2.624182321779821, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:17:54,445] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=0, lr=[3.741293532338309e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:17:54,446] [INFO] [timer.py:260:stop] epoch=0/micro_step=6080/global_step=190, RunningAvgSamplesPerSec=2.423681554856938, CurrSamplesPerSec=2.4844656121009554, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:22:26,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=0, lr=[3.940298507462687e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:22:26,297] [INFO] [timer.py:260:stop] epoch=0/micro_step=6400/global_step=200, RunningAvgSamplesPerSec=2.4265577975997252, CurrSamplesPerSec=2.621865592283935, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[epoch=1][batch=200/402]:
	 Train time/batch: 199
	 Train time/sample: 12736
	 Train time/batch_in_epoch: 199
	 Train time/sample_in_epoch: 12736
	 Train time/token: 12997568
	 Train time/token_in_epoch: 12997568
	 Train memory/allocated_mem: 3.3428
	 Train memory/active_mem: 3.3428
	 Train memory/inactive_mem: 0.0378
	 Train memory/reserved_mem: 21.2840
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2326
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 29.4294
	 Train throughput/batches_per_sec: 0.0368
	 Train throughput/samples_per_sec: 2.3542
	 Train throughput/device/batches_per_sec: 0.0368
	 Train throughput/device/samples_per_sec: 2.3542
	 Train time/train: 1.5418
	 Train time/val: 0.0000
	 Train time/total: 1.5418
[2025-04-11 12:26:56,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=0, lr=[4.139303482587065e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:26:56,734] [INFO] [timer.py:260:stop] epoch=0/micro_step=6720/global_step=210, RunningAvgSamplesPerSec=2.430061341322803, CurrSamplesPerSec=2.524080852631719, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:31:25,867] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=0, lr=[4.338308457711443e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:31:25,868] [INFO] [timer.py:260:stop] epoch=0/micro_step=7040/global_step=220, RunningAvgSamplesPerSec=2.4334573127208095, CurrSamplesPerSec=2.4977622066865104, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:35:50,168] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=0, lr=[4.537313432835821e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:35:50,169] [INFO] [timer.py:260:stop] epoch=0/micro_step=7360/global_step=230, RunningAvgSamplesPerSec=2.438369208897737, CurrSamplesPerSec=2.471174264002177, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:40:28,108] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=0, lr=[4.736318407960199e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:40:28,109] [INFO] [timer.py:260:stop] epoch=0/micro_step=7680/global_step=240, RunningAvgSamplesPerSec=2.4380357762140057, CurrSamplesPerSec=2.4187985821224762, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:45:03,912] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=0, lr=[4.935323383084577e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:45:03,913] [INFO] [timer.py:260:stop] epoch=0/micro_step=8000/global_step=250, RunningAvgSamplesPerSec=2.438393683721481, CurrSamplesPerSec=2.432399824143686, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[epoch=1][batch=250/402]:
	 Train time/batch: 249
	 Train time/sample: 15936
	 Train time/batch_in_epoch: 249
	 Train time/sample_in_epoch: 15936
	 Train time/token: 16262272
	 Train time/token_in_epoch: 16262272
	 Train memory/allocated_mem: 3.3430
	 Train memory/active_mem: 3.3430
	 Train memory/inactive_mem: 0.0397
	 Train memory/reserved_mem: 21.2840
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2118
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 28.9217
	 Train throughput/batches_per_sec: 0.0363
	 Train throughput/samples_per_sec: 2.3205
	 Train throughput/device/batches_per_sec: 0.0363
	 Train throughput/device/samples_per_sec: 2.3205
	 Train time/train: 1.9190
	 Train time/val: 0.0000
	 Train time/total: 1.9190
[2025-04-11 12:49:27,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=0, lr=[5.134328358208955e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:49:27,843] [INFO] [timer.py:260:stop] epoch=0/micro_step=8320/global_step=260, RunningAvgSamplesPerSec=2.4428241127068957, CurrSamplesPerSec=2.57232383763329, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:53:56,316] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=0, lr=[5.333333333333333e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:53:56,317] [INFO] [timer.py:260:stop] epoch=0/micro_step=8640/global_step=270, RunningAvgSamplesPerSec=2.4454250135688973, CurrSamplesPerSec=2.5415358502462797, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 12:58:30,105] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=0, lr=[5.5323383084577114e-05], mom=[[0.9, 0.98]]
[2025-04-11 12:58:30,107] [INFO] [timer.py:260:stop] epoch=0/micro_step=8960/global_step=280, RunningAvgSamplesPerSec=2.4461364429955026, CurrSamplesPerSec=2.4054134798699756, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 13:03:01,090] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=0, lr=[5.7313432835820894e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:03:01,091] [INFO] [timer.py:260:stop] epoch=0/micro_step=9280/global_step=290, RunningAvgSamplesPerSec=2.447717144235015, CurrSamplesPerSec=2.415813025650044, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[epoch=1][batch=300/402]:
	 Train time/batch: 299
	 Train time/sample: 19136
	 Train time/batch_in_epoch: 299
	 Train time/sample_in_epoch: 19136
	 Train time/token: 19527616
	 Train time/token_in_epoch: 19527616
	 Train memory/allocated_mem: 3.3432
	 Train memory/active_mem: 3.3432
	 Train memory/inactive_mem: 0.0521
	 Train memory/reserved_mem: 21.2840
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2036
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 28.4144
	 Train throughput/batches_per_sec: 0.0373
	 Train throughput/samples_per_sec: 2.3892
	 Train throughput/device/batches_per_sec: 0.0373
	 Train throughput/device/samples_per_sec: 2.3892
	 Train time/train: 2.2926
	 Train time/val: 0.0000
	 Train time/total: 2.2926
[2025-04-11 13:07:28,968] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=0, lr=[5.9303482587064675e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:07:28,969] [INFO] [timer.py:260:stop] epoch=0/micro_step=9600/global_step=300, RunningAvgSamplesPerSec=2.4501089226132966, CurrSamplesPerSec=2.5515253159433793, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 13:12:12,075] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=0, lr=[6.129353233830846e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:12:12,076] [INFO] [timer.py:260:stop] epoch=0/micro_step=9920/global_step=310, RunningAvgSamplesPerSec=2.447991938690379, CurrSamplesPerSec=2.3666113760325427, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 13:16:51,339] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=0, lr=[6.328358208955224e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:16:51,340] [INFO] [timer.py:260:stop] epoch=0/micro_step=10240/global_step=320, RunningAvgSamplesPerSec=2.446822609308049, CurrSamplesPerSec=2.4822846956318734, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 13:21:21,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=0, lr=[6.527363184079602e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:21:21,634] [INFO] [timer.py:260:stop] epoch=0/micro_step=10560/global_step=330, RunningAvgSamplesPerSec=2.448154465549493, CurrSamplesPerSec=2.4750446613252413, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 13:25:52,171] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=0, lr=[6.72636815920398e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:25:52,172] [INFO] [timer.py:260:stop] epoch=0/micro_step=10880/global_step=340, RunningAvgSamplesPerSec=2.4492245830201895, CurrSamplesPerSec=2.5225874114498708, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 13:30:25,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=0, lr=[6.925373134328358e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:30:25,958] [INFO] [timer.py:260:stop] epoch=0/micro_step=11200/global_step=350, RunningAvgSamplesPerSec=2.4495229199702093, CurrSamplesPerSec=2.530124829898913, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[epoch=1][batch=350/402]:
	 Train time/batch: 349
	 Train time/sample: 22336
	 Train time/batch_in_epoch: 349
	 Train time/sample_in_epoch: 22336
	 Train time/token: 22793216
	 Train time/token_in_epoch: 22793216
	 Train memory/allocated_mem: 3.3430
	 Train memory/active_mem: 3.3430
	 Train memory/inactive_mem: 0.0376
	 Train memory/reserved_mem: 21.2840
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2367
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 28.0386
	 Train throughput/batches_per_sec: 0.0365
	 Train throughput/samples_per_sec: 2.3376
	 Train throughput/device/batches_per_sec: 0.0365
	 Train throughput/device/samples_per_sec: 2.3376
	 Train time/train: 2.6751
	 Train time/val: 0.0000
	 Train time/total: 2.6751
[2025-04-11 13:34:59,098] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=0, lr=[7.124378109452738e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:34:59,099] [INFO] [timer.py:260:stop] epoch=0/micro_step=11520/global_step=360, RunningAvgSamplesPerSec=2.4499018177709977, CurrSamplesPerSec=2.37108538385549, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 13:39:38,195] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=0, lr=[7.323383084577115e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:39:38,196] [INFO] [timer.py:260:stop] epoch=0/micro_step=11840/global_step=370, RunningAvgSamplesPerSec=2.44884255644418, CurrSamplesPerSec=2.331143517329589, MemAllocated=3.61GB, MaxMemAllocated=17.35GB
[2025-04-11 13:44:20,109] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=0, lr=[7.522388059701494e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:44:20,111] [INFO] [timer.py:260:stop] epoch=0/micro_step=12160/global_step=380, RunningAvgSamplesPerSec=2.4472175116342374, CurrSamplesPerSec=2.329449186150751, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 13:49:01,478] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=0, lr=[7.721393034825871e-05], mom=[[0.9, 0.98]]
[2025-04-11 13:49:01,479] [INFO] [timer.py:260:stop] epoch=0/micro_step=12480/global_step=390, RunningAvgSamplesPerSec=2.445806584132383, CurrSamplesPerSec=2.5776543867933057, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[2025-04-11 13:53:39,354] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=0, lr=[7.92039800995025e-05], mom=[[0.9, 0.98]]
[epoch=1][batch=400/402]:
	 Train time/batch: 399
	 Train time/sample: 25536
	 Train time/batch_in_epoch: 399
	 Train time/sample_in_epoch: 25536
	 Train time/token: 26060160
	 Train time/token_in_epoch: 26060160
	 Train memory/allocated_mem: 3.3432
	 Train memory/active_mem: 3.3432
	 Train memory/inactive_mem: 0.0500
	 Train memory/reserved_mem: 22.3160
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2498
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 27.7025
	 Train throughput/batches_per_sec: 0.0360
	 Train throughput/samples_per_sec: 2.3032
	 Train throughput/device/batches_per_sec: 0.0360
	 Train throughput/device/samples_per_sec: 2.3032
	 Train time/train: 3.0621
	 Train time/val: 0.0000
	 Train time/total: 3.0621
[2025-04-11 13:53:39,355] [INFO] [timer.py:260:stop] epoch=0/micro_step=12800/global_step=400, RunningAvgSamplesPerSec=2.4452088406066586, CurrSamplesPerSec=2.4528232748835315, MemAllocated=3.62GB, MaxMemAllocated=17.35GB
[Eval batch=1/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on in-domain-standard-q-answer-eval data:
	 Eval metrics/in-domain-standard-q-answer-eval/QA-EM: 0.0064
	 Eval metrics/in-domain-standard-q-answer-eval/QA-F1: 0.1294
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@1-att: 0.0000
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@10-att: 0.0312
[Eval batch=1/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on out-of-domain-standard-q-answer-eval data:
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-EM: 0.0086
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-F1: 0.1326
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@1-att: 0.0000
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@10-att: 0.0000
[2025-04-11 14:33:19,630] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=0, lr=[7.986069651741294e-05], mom=[[0.9, 0.98]]
[2025-04-11 14:33:19,632] [INFO] [timer.py:260:stop] epoch=0/micro_step=13120/global_step=410, RunningAvgSamplesPerSec=2.440455987425626, CurrSamplesPerSec=2.1753498447050745, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 14:38:32,049] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=0, lr=[7.966169154228856e-05], mom=[[0.9, 0.98]]
[2025-04-11 14:38:32,050] [INFO] [timer.py:260:stop] epoch=0/micro_step=13440/global_step=420, RunningAvgSamplesPerSec=2.432487091666856, CurrSamplesPerSec=2.103043347337042, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 14:43:36,708] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=0, lr=[7.946268656716418e-05], mom=[[0.9, 0.98]]
[2025-04-11 14:43:36,709] [INFO] [timer.py:260:stop] epoch=0/micro_step=13760/global_step=430, RunningAvgSamplesPerSec=2.4265432170255616, CurrSamplesPerSec=2.2397202741936604, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 14:48:36,175] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=0, lr=[7.926368159203981e-05], mom=[[0.9, 0.98]]
[2025-04-11 14:48:36,177] [INFO] [timer.py:260:stop] epoch=0/micro_step=14080/global_step=440, RunningAvgSamplesPerSec=2.421966702651526, CurrSamplesPerSec=2.1994445218827785, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=2][batch=48/402]:
	 Train time/epoch: 1
	 Train time/batch: 449
	 Train time/sample: 28677
	 Train time/batch_in_epoch: 47
	 Train time/sample_in_epoch: 3008
	 Train time/token: 29262416
	 Train time/token_in_epoch: 3066816
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0417
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2224
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 32.7900
	 Train throughput/batches_per_sec: 0.0328
	 Train throughput/samples_per_sec: 2.1010
	 Train throughput/device/batches_per_sec: 0.0328
	 Train throughput/device/samples_per_sec: 2.1010
	 Train time/train: 3.4757
	 Train time/val: 0.5790
	 Train time/total: 4.0546
[2025-04-11 14:53:40,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=0, lr=[7.906467661691544e-05], mom=[[0.9, 0.98]]
[2025-04-11 14:53:40,191] [INFO] [timer.py:260:stop] epoch=0/micro_step=14400/global_step=450, RunningAvgSamplesPerSec=2.4167794395078968, CurrSamplesPerSec=2.242483501461181, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 14:58:38,479] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=0, lr=[7.886567164179105e-05], mom=[[0.9, 0.98]]
[2025-04-11 14:58:38,481] [INFO] [timer.py:260:stop] epoch=0/micro_step=14720/global_step=460, RunningAvgSamplesPerSec=2.412783460802819, CurrSamplesPerSec=2.222407898844917, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:03:37,920] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=0, lr=[7.866666666666666e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:03:37,921] [INFO] [timer.py:260:stop] epoch=0/micro_step=15040/global_step=470, RunningAvgSamplesPerSec=2.408841205699996, CurrSamplesPerSec=2.2258381731871046, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:08:38,771] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=0, lr=[7.846766169154229e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:08:38,772] [INFO] [timer.py:260:stop] epoch=0/micro_step=15360/global_step=480, RunningAvgSamplesPerSec=2.4047336054132953, CurrSamplesPerSec=2.2182158066995976, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:13:43,436] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=0, lr=[7.826865671641792e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:13:43,437] [INFO] [timer.py:260:stop] epoch=0/micro_step=15680/global_step=490, RunningAvgSamplesPerSec=2.4002207245182046, CurrSamplesPerSec=2.2284605193111524, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=2][batch=98/402]:
	 Train time/batch: 499
	 Train time/sample: 31877
	 Train time/batch_in_epoch: 97
	 Train time/sample_in_epoch: 6208
	 Train time/token: 32528912
	 Train time/token_in_epoch: 6333312
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0375
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2239
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 32.6268
	 Train throughput/batches_per_sec: 0.0333
	 Train throughput/samples_per_sec: 2.1283
	 Train throughput/device/batches_per_sec: 0.0333
	 Train throughput/device/samples_per_sec: 2.1283
	 Train time/train: 3.8934
	 Train time/val: 0.5790
	 Train time/total: 4.4723
[2025-04-11 15:18:43,904] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=0, lr=[7.806965174129354e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:18:43,905] [INFO] [timer.py:260:stop] epoch=0/micro_step=16000/global_step=500, RunningAvgSamplesPerSec=2.3965780850454035, CurrSamplesPerSec=2.2285624770723538, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:23:47,543] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=0, lr=[7.787064676616916e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:23:47,544] [INFO] [timer.py:260:stop] epoch=0/micro_step=16320/global_step=510, RunningAvgSamplesPerSec=2.3925271387052516, CurrSamplesPerSec=2.2839097831515853, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:28:50,408] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=0, lr=[7.767164179104478e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:28:50,409] [INFO] [timer.py:260:stop] epoch=0/micro_step=16640/global_step=520, RunningAvgSamplesPerSec=2.3887662386604136, CurrSamplesPerSec=2.1646774209936623, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:33:54,684] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=0, lr=[7.747263681592041e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:33:54,685] [INFO] [timer.py:260:stop] epoch=0/micro_step=16960/global_step=530, RunningAvgSamplesPerSec=2.384962912706076, CurrSamplesPerSec=2.1765568229315346, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:38:58,988] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=0, lr=[7.727363184079602e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:38:58,989] [INFO] [timer.py:260:stop] epoch=0/micro_step=17280/global_step=540, RunningAvgSamplesPerSec=2.381330092357336, CurrSamplesPerSec=2.1853077766744047, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=2][batch=148/402]:
	 Train time/batch: 549
	 Train time/sample: 35077
	 Train time/batch_in_epoch: 147
	 Train time/sample_in_epoch: 9408
	 Train time/token: 35795856
	 Train time/token_in_epoch: 9600256
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0376
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.1947
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 32.4428
	 Train throughput/batches_per_sec: 0.0329
	 Train throughput/samples_per_sec: 2.1059
	 Train throughput/device/batches_per_sec: 0.0329
	 Train throughput/device/samples_per_sec: 2.1059
	 Train time/train: 4.3151
	 Train time/val: 0.5790
	 Train time/total: 4.8940
[2025-04-11 15:44:01,992] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=0, lr=[7.707462686567165e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:44:01,994] [INFO] [timer.py:260:stop] epoch=0/micro_step=17600/global_step=550, RunningAvgSamplesPerSec=2.3781103106431503, CurrSamplesPerSec=2.2520382154971275, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:49:05,249] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=0, lr=[7.687562189054726e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:49:05,250] [INFO] [timer.py:260:stop] epoch=0/micro_step=17920/global_step=560, RunningAvgSamplesPerSec=2.3748472365705457, CurrSamplesPerSec=2.3158957339933215, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:54:13,628] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=0, lr=[7.667661691542289e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:54:13,630] [INFO] [timer.py:260:stop] epoch=0/micro_step=18240/global_step=570, RunningAvgSamplesPerSec=2.3709642514503013, CurrSamplesPerSec=2.1204605663965803, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 15:59:18,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=0, lr=[7.647761194029852e-05], mom=[[0.9, 0.98]]
[2025-04-11 15:59:18,056] [INFO] [timer.py:260:stop] epoch=0/micro_step=18560/global_step=580, RunningAvgSamplesPerSec=2.3677840238372103, CurrSamplesPerSec=2.182968055701596, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 16:04:14,608] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=0, lr=[7.627860696517413e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:04:14,609] [INFO] [timer.py:260:stop] epoch=0/micro_step=18880/global_step=590, RunningAvgSamplesPerSec=2.3659035795987213, CurrSamplesPerSec=2.2333405297191695, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=2][batch=198/402]:
	 Train time/batch: 599
	 Train time/sample: 38277
	 Train time/batch_in_epoch: 197
	 Train time/sample_in_epoch: 12608
	 Train time/token: 39059984
	 Train time/token_in_epoch: 12864384
	 Train memory/allocated_mem: 3.3471
	 Train memory/active_mem: 3.3471
	 Train memory/inactive_mem: 0.0419
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.2071
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 32.2096
	 Train throughput/batches_per_sec: 0.0334
	 Train throughput/samples_per_sec: 2.1356
	 Train throughput/device/batches_per_sec: 0.0334
	 Train throughput/device/samples_per_sec: 2.1356
	 Train time/train: 4.7351
	 Train time/val: 0.5790
	 Train time/total: 5.3141
[2025-04-11 16:09:14,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=0, lr=[7.607960199004976e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:09:14,662] [INFO] [timer.py:260:stop] epoch=0/micro_step=19200/global_step=600, RunningAvgSamplesPerSec=2.363536734134463, CurrSamplesPerSec=2.2011859102135305, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 16:14:09,337] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=0, lr=[7.588059701492538e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:14:09,338] [INFO] [timer.py:260:stop] epoch=0/micro_step=19520/global_step=610, RunningAvgSamplesPerSec=2.3619536455052046, CurrSamplesPerSec=2.2209833978349747, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 16:18:59,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=0, lr=[7.5681592039801e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:18:59,407] [INFO] [timer.py:260:stop] epoch=0/micro_step=19840/global_step=620, RunningAvgSamplesPerSec=2.361159246746011, CurrSamplesPerSec=2.4354094864162112, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 16:23:55,442] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=0, lr=[7.548258706467662e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:23:55,443] [INFO] [timer.py:260:stop] epoch=0/micro_step=20160/global_step=630, RunningAvgSamplesPerSec=2.3595896373820464, CurrSamplesPerSec=2.214398519617689, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 16:28:52,120] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=0, lr=[7.528358208955225e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:28:52,121] [INFO] [timer.py:260:stop] epoch=0/micro_step=20480/global_step=640, RunningAvgSamplesPerSec=2.357989539713651, CurrSamplesPerSec=2.2280836840365486, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=2][batch=248/402]:
	 Train time/batch: 649
	 Train time/sample: 41477
	 Train time/batch_in_epoch: 247
	 Train time/sample_in_epoch: 15808
	 Train time/token: 42322384
	 Train time/token_in_epoch: 16126784
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0397
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.1988
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 31.8940
	 Train throughput/batches_per_sec: 0.0336
	 Train throughput/samples_per_sec: 2.1524
	 Train throughput/device/batches_per_sec: 0.0336
	 Train throughput/device/samples_per_sec: 2.1524
	 Train time/train: 5.1449
	 Train time/val: 0.5790
	 Train time/total: 5.7238
[2025-04-11 16:33:49,658] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=0, lr=[7.508457711442788e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:33:49,659] [INFO] [timer.py:260:stop] epoch=0/micro_step=20800/global_step=650, RunningAvgSamplesPerSec=2.3562962753006484, CurrSamplesPerSec=2.2150366118891864, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 16:38:48,458] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=0, lr=[7.488557213930349e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:38:48,459] [INFO] [timer.py:260:stop] epoch=0/micro_step=21120/global_step=660, RunningAvgSamplesPerSec=2.3544898387955464, CurrSamplesPerSec=2.307917856164228, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 16:43:48,727] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=0, lr=[7.46865671641791e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:43:48,728] [INFO] [timer.py:260:stop] epoch=0/micro_step=21440/global_step=670, RunningAvgSamplesPerSec=2.352674494081232, CurrSamplesPerSec=2.263496403763259, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 16:48:50,433] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=0, lr=[7.448756218905473e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:48:50,434] [INFO] [timer.py:260:stop] epoch=0/micro_step=21760/global_step=680, RunningAvgSamplesPerSec=2.3507309250545143, CurrSamplesPerSec=2.2232270919400055, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 16:53:50,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=0, lr=[7.428855721393036e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:53:50,987] [INFO] [timer.py:260:stop] epoch=0/micro_step=22080/global_step=690, RunningAvgSamplesPerSec=2.3489956420265123, CurrSamplesPerSec=2.223227128766279, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=2][batch=298/402]:
	 Train time/batch: 699
	 Train time/sample: 44677
	 Train time/batch_in_epoch: 297
	 Train time/sample_in_epoch: 19008
	 Train time/token: 45590160
	 Train time/token_in_epoch: 19394560
	 Train memory/allocated_mem: 3.3490
	 Train memory/active_mem: 3.3490
	 Train memory/inactive_mem: 0.0358
	 Train memory/reserved_mem: 33.3490
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.1703
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 31.6004
	 Train throughput/batches_per_sec: 0.0333
	 Train throughput/samples_per_sec: 2.1290
	 Train throughput/device/batches_per_sec: 0.0333
	 Train throughput/device/samples_per_sec: 2.1290
	 Train time/train: 5.5621
	 Train time/val: 0.5790
	 Train time/total: 6.1410
[2025-04-11 16:58:51,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=0, lr=[7.408955223880598e-05], mom=[[0.9, 0.98]]
[2025-04-11 16:58:51,407] [INFO] [timer.py:260:stop] epoch=0/micro_step=22400/global_step=700, RunningAvgSamplesPerSec=2.347327892006899, CurrSamplesPerSec=2.2440718203752446, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 17:03:55,166] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=0, lr=[7.38905472636816e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:03:55,167] [INFO] [timer.py:260:stop] epoch=0/micro_step=22720/global_step=710, RunningAvgSamplesPerSec=2.345287758896768, CurrSamplesPerSec=2.2362531851673055, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 17:08:54,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=0, lr=[7.369154228855722e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:08:54,386] [INFO] [timer.py:260:stop] epoch=0/micro_step=23040/global_step=720, RunningAvgSamplesPerSec=2.343831705340479, CurrSamplesPerSec=2.2192102085397636, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 17:13:57,534] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=0, lr=[7.349253731343285e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:13:57,535] [INFO] [timer.py:260:stop] epoch=0/micro_step=23360/global_step=730, RunningAvgSamplesPerSec=2.34198169635395, CurrSamplesPerSec=2.2087836313756495, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 17:18:58,440] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=0, lr=[7.329353233830846e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:18:58,441] [INFO] [timer.py:260:stop] epoch=0/micro_step=23680/global_step=740, RunningAvgSamplesPerSec=2.3403719715088904, CurrSamplesPerSec=2.210336457208738, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=2][batch=348/402]:
	 Train time/batch: 749
	 Train time/sample: 47877
	 Train time/batch_in_epoch: 347
	 Train time/sample_in_epoch: 22208
	 Train time/token: 48857168
	 Train time/token_in_epoch: 22661568
	 Train memory/allocated_mem: 3.3470
	 Train memory/active_mem: 3.3470
	 Train memory/inactive_mem: 0.0357
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.1244
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 31.3016
	 Train throughput/batches_per_sec: 0.0329
	 Train throughput/samples_per_sec: 2.1034
	 Train throughput/device/batches_per_sec: 0.0329
	 Train throughput/device/samples_per_sec: 2.1034
	 Train time/train: 5.9819
	 Train time/val: 0.5790
	 Train time/total: 6.5608
[2025-04-11 17:24:03,344] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=0, lr=[7.309452736318409e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:24:03,345] [INFO] [timer.py:260:stop] epoch=0/micro_step=24000/global_step=750, RunningAvgSamplesPerSec=2.3383933393986074, CurrSamplesPerSec=2.1204321416538368, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 17:29:09,297] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=0, lr=[7.28955223880597e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:29:09,298] [INFO] [timer.py:260:stop] epoch=0/micro_step=24320/global_step=760, RunningAvgSamplesPerSec=2.3363573350992413, CurrSamplesPerSec=2.1431534835400328, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 17:34:12,351] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=0, lr=[7.269651741293533e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:34:12,352] [INFO] [timer.py:260:stop] epoch=0/micro_step=24640/global_step=770, RunningAvgSamplesPerSec=2.334661345709866, CurrSamplesPerSec=2.219560244621773, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 17:39:16,458] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=0, lr=[7.249751243781096e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:39:16,459] [INFO] [timer.py:260:stop] epoch=0/micro_step=24960/global_step=780, RunningAvgSamplesPerSec=2.3328726754509552, CurrSamplesPerSec=2.171985661868572, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 17:44:15,168] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=0, lr=[7.229850746268657e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:44:15,169] [INFO] [timer.py:260:stop] epoch=0/micro_step=25280/global_step=790, RunningAvgSamplesPerSec=2.3317986465987914, CurrSamplesPerSec=2.2202290808350758, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=2][batch=398/402]:
	 Train time/batch: 799
	 Train time/sample: 51077
	 Train time/batch_in_epoch: 397
	 Train time/sample_in_epoch: 25408
	 Train time/token: 52122512
	 Train time/token_in_epoch: 25926912
	 Train memory/allocated_mem: 3.3490
	 Train memory/active_mem: 3.3490
	 Train memory/inactive_mem: 0.0379
	 Train memory/reserved_mem: 33.3490
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.1262
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 30.9861
	 Train throughput/batches_per_sec: 0.0336
	 Train throughput/samples_per_sec: 2.1506
	 Train throughput/device/batches_per_sec: 0.0336
	 Train throughput/device/samples_per_sec: 2.1506
	 Train time/train: 6.4013
	 Train time/val: 0.5790
	 Train time/total: 6.9802
[2025-04-11 17:49:12,645] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=0, lr=[7.20995024875622e-05], mom=[[0.9, 0.98]]
[2025-04-11 17:49:12,647] [INFO] [timer.py:260:stop] epoch=0/micro_step=25600/global_step=800, RunningAvgSamplesPerSec=2.330811867906924, CurrSamplesPerSec=2.229340371581787, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[Eval batch=1/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on in-domain-standard-q-answer-eval data:
	 Eval metrics/in-domain-standard-q-answer-eval/QA-EM: 0.0072
	 Eval metrics/in-domain-standard-q-answer-eval/QA-F1: 0.1278
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@1-att: 0.0000
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@10-att: 0.0278
[Eval batch=1/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on out-of-domain-standard-q-answer-eval data:
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-EM: 0.0076
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-F1: 0.1310
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@1-att: 0.0000
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@10-att: 0.0263
[2025-04-11 18:20:38,202] [INFO] [logging.py:96:log_dist] [Rank 0] step=810, skipped=0, lr=[7.188059701492538e-05], mom=[[0.9, 0.98]]
[2025-04-11 18:20:38,203] [INFO] [timer.py:260:stop] epoch=0/micro_step=25920/global_step=810, RunningAvgSamplesPerSec=2.329359601416695, CurrSamplesPerSec=2.192950332861658, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 18:25:40,880] [INFO] [logging.py:96:log_dist] [Rank 0] step=820, skipped=0, lr=[7.168159203980101e-05], mom=[[0.9, 0.98]]
[2025-04-11 18:25:40,882] [INFO] [timer.py:260:stop] epoch=0/micro_step=26240/global_step=820, RunningAvgSamplesPerSec=2.327878038976172, CurrSamplesPerSec=2.2592695774968967, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 18:30:39,660] [INFO] [logging.py:96:log_dist] [Rank 0] step=830, skipped=0, lr=[7.148258706467662e-05], mom=[[0.9, 0.98]]
[2025-04-11 18:30:39,661] [INFO] [timer.py:260:stop] epoch=0/micro_step=26560/global_step=830, RunningAvgSamplesPerSec=2.3268049884950375, CurrSamplesPerSec=2.24208303229507, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 18:35:40,133] [INFO] [logging.py:96:log_dist] [Rank 0] step=840, skipped=0, lr=[7.128358208955225e-05], mom=[[0.9, 0.98]]
[2025-04-11 18:35:40,134] [INFO] [timer.py:260:stop] epoch=0/micro_step=26880/global_step=840, RunningAvgSamplesPerSec=2.3255766469223946, CurrSamplesPerSec=2.2288548410132605, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=3][batch=46/402]:
	 Train time/epoch: 2
	 Train time/batch: 849
	 Train time/sample: 54218
	 Train time/batch_in_epoch: 45
	 Train time/sample_in_epoch: 2880
	 Train time/token: 55325929
	 Train time/token_in_epoch: 2940544
	 Train memory/allocated_mem: 3.3467
	 Train memory/active_mem: 3.3467
	 Train memory/inactive_mem: 0.0339
	 Train memory/reserved_mem: 33.2400
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.0587
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 28.9205
	 Train throughput/batches_per_sec: 0.0336
	 Train throughput/samples_per_sec: 2.1481
	 Train throughput/device/batches_per_sec: 0.0336
	 Train throughput/device/samples_per_sec: 2.1481
	 Train time/train: 6.8109
	 Train time/val: 1.0187
	 Train time/total: 7.8295
[2025-04-11 18:40:39,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=850, skipped=0, lr=[7.108457711442786e-05], mom=[[0.9, 0.98]]
[2025-04-11 18:40:39,226] [INFO] [timer.py:260:stop] epoch=0/micro_step=27200/global_step=850, RunningAvgSamplesPerSec=2.3245094378626336, CurrSamplesPerSec=2.182017584966369, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 18:45:37,006] [INFO] [logging.py:96:log_dist] [Rank 0] step=860, skipped=0, lr=[7.088557213930349e-05], mom=[[0.9, 0.98]]
[2025-04-11 18:45:37,007] [INFO] [timer.py:260:stop] epoch=0/micro_step=27520/global_step=860, RunningAvgSamplesPerSec=2.323587756205237, CurrSamplesPerSec=2.2277656567960857, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 18:50:33,612] [INFO] [logging.py:96:log_dist] [Rank 0] step=870, skipped=0, lr=[7.068656716417911e-05], mom=[[0.9, 0.98]]
[2025-04-11 18:50:33,613] [INFO] [timer.py:260:stop] epoch=0/micro_step=27840/global_step=870, RunningAvgSamplesPerSec=2.3228039981440065, CurrSamplesPerSec=2.2151850917335194, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 18:55:33,205] [INFO] [logging.py:96:log_dist] [Rank 0] step=880, skipped=0, lr=[7.048756218905473e-05], mom=[[0.9, 0.98]]
[2025-04-11 18:55:33,206] [INFO] [timer.py:260:stop] epoch=0/micro_step=28160/global_step=880, RunningAvgSamplesPerSec=2.321776258959341, CurrSamplesPerSec=2.1983767377862806, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 19:00:36,579] [INFO] [logging.py:96:log_dist] [Rank 0] step=890, skipped=0, lr=[7.028855721393035e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:00:36,580] [INFO] [timer.py:260:stop] epoch=0/micro_step=28480/global_step=890, RunningAvgSamplesPerSec=2.3204590438459753, CurrSamplesPerSec=2.1873452147367014, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=3][batch=96/402]:
	 Train time/batch: 899
	 Train time/sample: 57418
	 Train time/batch_in_epoch: 95
	 Train time/sample_in_epoch: 6080
	 Train time/token: 58593193
	 Train time/token_in_epoch: 6207808
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0375
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.0671
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 28.5779
	 Train throughput/batches_per_sec: 0.0328
	 Train throughput/samples_per_sec: 2.1004
	 Train throughput/device/batches_per_sec: 0.0328
	 Train throughput/device/samples_per_sec: 2.1004
	 Train time/train: 7.2282
	 Train time/val: 1.0187
	 Train time/total: 8.2468
[2025-04-11 19:05:38,852] [INFO] [logging.py:96:log_dist] [Rank 0] step=900, skipped=0, lr=[7.008955223880598e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:05:38,853] [INFO] [timer.py:260:stop] epoch=0/micro_step=28800/global_step=900, RunningAvgSamplesPerSec=2.3192921658286054, CurrSamplesPerSec=2.2144044199349695, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 19:10:42,272] [INFO] [logging.py:96:log_dist] [Rank 0] step=910, skipped=0, lr=[6.989054726368161e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:10:42,273] [INFO] [timer.py:260:stop] epoch=0/micro_step=29120/global_step=910, RunningAvgSamplesPerSec=2.318010703913159, CurrSamplesPerSec=2.3047521343680533, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 19:15:42,471] [INFO] [logging.py:96:log_dist] [Rank 0] step=920, skipped=0, lr=[6.969154228855722e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:15:42,472] [INFO] [timer.py:260:stop] epoch=0/micro_step=29440/global_step=920, RunningAvgSamplesPerSec=2.317049458636793, CurrSamplesPerSec=2.3968552911980696, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 19:20:47,411] [INFO] [logging.py:96:log_dist] [Rank 0] step=930, skipped=0, lr=[6.949253731343283e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:20:47,412] [INFO] [timer.py:260:stop] epoch=0/micro_step=29760/global_step=930, RunningAvgSamplesPerSec=2.3157065366661387, CurrSamplesPerSec=2.166402809069156, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 19:25:49,296] [INFO] [logging.py:96:log_dist] [Rank 0] step=940, skipped=0, lr=[6.929353233830847e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:25:49,297] [INFO] [timer.py:260:stop] epoch=0/micro_step=30080/global_step=940, RunningAvgSamplesPerSec=2.3146628847540374, CurrSamplesPerSec=2.2354603138368256, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=3][batch=146/402]:
	 Train time/batch: 949
	 Train time/sample: 60618
	 Train time/batch_in_epoch: 145
	 Train time/sample_in_epoch: 9280
	 Train time/token: 61858601
	 Train time/token_in_epoch: 9473216
	 Train memory/allocated_mem: 3.3474
	 Train memory/active_mem: 3.3474
	 Train memory/inactive_mem: 0.0563
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.0712
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 28.2346
	 Train throughput/batches_per_sec: 0.0332
	 Train throughput/samples_per_sec: 2.1239
	 Train throughput/device/batches_per_sec: 0.0332
	 Train throughput/device/samples_per_sec: 2.1239
	 Train time/train: 7.6477
	 Train time/val: 1.0187
	 Train time/total: 8.6664
[2025-04-11 19:30:51,445] [INFO] [logging.py:96:log_dist] [Rank 0] step=950, skipped=0, lr=[6.909452736318409e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:30:51,446] [INFO] [timer.py:260:stop] epoch=0/micro_step=30400/global_step=950, RunningAvgSamplesPerSec=2.3135874531636986, CurrSamplesPerSec=2.210952670365213, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 19:35:47,759] [INFO] [logging.py:96:log_dist] [Rank 0] step=960, skipped=0, lr=[6.889552238805971e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:35:47,761] [INFO] [timer.py:260:stop] epoch=0/micro_step=30720/global_step=960, RunningAvgSamplesPerSec=2.3130323868118117, CurrSamplesPerSec=2.173568152519116, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 19:40:51,054] [INFO] [logging.py:96:log_dist] [Rank 0] step=970, skipped=0, lr=[6.869651741293533e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:40:51,056] [INFO] [timer.py:260:stop] epoch=0/micro_step=31040/global_step=970, RunningAvgSamplesPerSec=2.3119478561091227, CurrSamplesPerSec=2.243689255947568, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 19:45:49,443] [INFO] [logging.py:96:log_dist] [Rank 0] step=980, skipped=0, lr=[6.849751243781095e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:45:49,444] [INFO] [timer.py:260:stop] epoch=0/micro_step=31360/global_step=980, RunningAvgSamplesPerSec=2.3112894322164643, CurrSamplesPerSec=2.3900641027752796, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 19:50:49,340] [INFO] [logging.py:96:log_dist] [Rank 0] step=990, skipped=0, lr=[6.829850746268657e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:50:49,341] [INFO] [timer.py:260:stop] epoch=0/micro_step=31680/global_step=990, RunningAvgSamplesPerSec=2.310506673178636, CurrSamplesPerSec=2.2085767139983705, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=3][batch=196/402]:
	 Train time/batch: 999
	 Train time/sample: 63818
	 Train time/batch_in_epoch: 195
	 Train time/sample_in_epoch: 12480
	 Train time/token: 65123753
	 Train time/token_in_epoch: 12738368
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0418
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.0046
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 27.8750
	 Train throughput/batches_per_sec: 0.0331
	 Train throughput/samples_per_sec: 2.1203
	 Train throughput/device/batches_per_sec: 0.0331
	 Train throughput/device/samples_per_sec: 2.1203
	 Train time/train: 8.0644
	 Train time/val: 1.0187
	 Train time/total: 9.0831
[2025-04-11 19:55:47,557] [INFO] [logging.py:96:log_dist] [Rank 0] step=1000, skipped=0, lr=[6.809950248756219e-05], mom=[[0.9, 0.98]]
[2025-04-11 19:55:47,558] [INFO] [timer.py:260:stop] epoch=0/micro_step=32000/global_step=1000, RunningAvgSamplesPerSec=2.309855949616739, CurrSamplesPerSec=2.3757322787254096, MemAllocated=3.58GB, MaxMemAllocated=17.36GB
[2025-04-11 20:00:46,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=1010, skipped=0, lr=[6.790049751243782e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:00:46,533] [INFO] [timer.py:260:stop] epoch=0/micro_step=32320/global_step=1010, RunningAvgSamplesPerSec=2.3092311154260594, CurrSamplesPerSec=2.1459072816781375, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 20:05:43,607] [INFO] [logging.py:96:log_dist] [Rank 0] step=1020, skipped=0, lr=[6.770149253731345e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:05:43,608] [INFO] [timer.py:260:stop] epoch=0/micro_step=32640/global_step=1020, RunningAvgSamplesPerSec=2.308741894238417, CurrSamplesPerSec=2.1741407529861108, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 20:10:44,906] [INFO] [logging.py:96:log_dist] [Rank 0] step=1030, skipped=0, lr=[6.750248756218906e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:10:44,907] [INFO] [timer.py:260:stop] epoch=0/micro_step=32960/global_step=1030, RunningAvgSamplesPerSec=2.3079357127462927, CurrSamplesPerSec=2.223950484765039, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 20:15:40,244] [INFO] [logging.py:96:log_dist] [Rank 0] step=1040, skipped=0, lr=[6.730348258706467e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:15:40,245] [INFO] [timer.py:260:stop] epoch=0/micro_step=33280/global_step=1040, RunningAvgSamplesPerSec=2.307553993562419, CurrSamplesPerSec=2.2639082255240255, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=3][batch=246/402]:
	 Train time/batch: 1049
	 Train time/sample: 67018
	 Train time/batch_in_epoch: 245
	 Train time/sample_in_epoch: 15680
	 Train time/token: 68386857
	 Train time/token_in_epoch: 16001472
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0396
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.0562
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 27.5080
	 Train throughput/batches_per_sec: 0.0325
	 Train throughput/samples_per_sec: 2.0794
	 Train throughput/device/batches_per_sec: 0.0325
	 Train throughput/device/samples_per_sec: 2.0794
	 Train time/train: 8.4804
	 Train time/val: 1.0187
	 Train time/total: 9.4991
[2025-04-11 20:20:45,317] [INFO] [logging.py:96:log_dist] [Rank 0] step=1050, skipped=0, lr=[6.71044776119403e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:20:45,318] [INFO] [timer.py:260:stop] epoch=0/micro_step=33600/global_step=1050, RunningAvgSamplesPerSec=2.306464108681065, CurrSamplesPerSec=2.347530342981703, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 20:25:45,809] [INFO] [logging.py:96:log_dist] [Rank 0] step=1060, skipped=0, lr=[6.690547263681593e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:25:45,811] [INFO] [timer.py:260:stop] epoch=0/micro_step=33920/global_step=1060, RunningAvgSamplesPerSec=2.305731008065304, CurrSamplesPerSec=2.2194166460091402, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 20:30:47,576] [INFO] [logging.py:96:log_dist] [Rank 0] step=1070, skipped=0, lr=[6.670646766169155e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:30:47,577] [INFO] [timer.py:260:stop] epoch=0/micro_step=34240/global_step=1070, RunningAvgSamplesPerSec=2.304913561240894, CurrSamplesPerSec=2.182389874111924, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 20:35:45,583] [INFO] [logging.py:96:log_dist] [Rank 0] step=1080, skipped=0, lr=[6.650746268656717e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:35:45,584] [INFO] [timer.py:260:stop] epoch=0/micro_step=34560/global_step=1080, RunningAvgSamplesPerSec=2.3043577128605652, CurrSamplesPerSec=2.176344712375052, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 20:40:50,010] [INFO] [logging.py:96:log_dist] [Rank 0] step=1090, skipped=0, lr=[6.630845771144279e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:40:50,011] [INFO] [timer.py:260:stop] epoch=0/micro_step=34880/global_step=1090, RunningAvgSamplesPerSec=2.303362854492685, CurrSamplesPerSec=2.182535677326135, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=3][batch=296/402]:
	 Train time/batch: 1099
	 Train time/sample: 70218
	 Train time/batch_in_epoch: 295
	 Train time/sample_in_epoch: 18880
	 Train time/token: 71653225
	 Train time/token_in_epoch: 19267840
	 Train memory/allocated_mem: 3.3474
	 Train memory/active_mem: 3.3474
	 Train memory/inactive_mem: 0.0416
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.0044
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 27.1420
	 Train throughput/batches_per_sec: 0.0328
	 Train throughput/samples_per_sec: 2.1011
	 Train throughput/device/batches_per_sec: 0.0328
	 Train throughput/device/samples_per_sec: 2.1011
	 Train time/train: 8.8984
	 Train time/val: 1.0187
	 Train time/total: 9.9171
[2025-04-11 20:45:56,238] [INFO] [logging.py:96:log_dist] [Rank 0] step=1100, skipped=0, lr=[6.610945273631842e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:45:56,239] [INFO] [timer.py:260:stop] epoch=0/micro_step=35200/global_step=1100, RunningAvgSamplesPerSec=2.30238702475582, CurrSamplesPerSec=2.1425042111128683, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 20:51:03,568] [INFO] [logging.py:96:log_dist] [Rank 0] step=1110, skipped=0, lr=[6.591044776119403e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:51:03,570] [INFO] [timer.py:260:stop] epoch=0/micro_step=35520/global_step=1110, RunningAvgSamplesPerSec=2.301353233478915, CurrSamplesPerSec=2.18603790665623, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 20:56:07,062] [INFO] [logging.py:96:log_dist] [Rank 0] step=1120, skipped=0, lr=[6.571144278606966e-05], mom=[[0.9, 0.98]]
[2025-04-11 20:56:07,063] [INFO] [timer.py:260:stop] epoch=0/micro_step=35840/global_step=1120, RunningAvgSamplesPerSec=2.3006399150121455, CurrSamplesPerSec=2.224170613046864, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 21:01:13,134] [INFO] [logging.py:96:log_dist] [Rank 0] step=1130, skipped=0, lr=[6.551243781094527e-05], mom=[[0.9, 0.98]]
[2025-04-11 21:01:13,136] [INFO] [timer.py:260:stop] epoch=0/micro_step=36160/global_step=1130, RunningAvgSamplesPerSec=2.2997435011830993, CurrSamplesPerSec=2.1220558506348426, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 21:06:18,843] [INFO] [logging.py:96:log_dist] [Rank 0] step=1140, skipped=0, lr=[6.53134328358209e-05], mom=[[0.9, 0.98]]
[2025-04-11 21:06:18,845] [INFO] [timer.py:260:stop] epoch=0/micro_step=36480/global_step=1140, RunningAvgSamplesPerSec=2.2988722003352438, CurrSamplesPerSec=2.204643547067715, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=3][batch=346/402]:
	 Train time/batch: 1149
	 Train time/sample: 73418
	 Train time/batch_in_epoch: 345
	 Train time/sample_in_epoch: 22080
	 Train time/token: 74920937
	 Train time/token_in_epoch: 22535552
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0376
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.0194
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 26.7882
	 Train throughput/batches_per_sec: 0.0328
	 Train throughput/samples_per_sec: 2.1018
	 Train throughput/device/batches_per_sec: 0.0328
	 Train throughput/device/samples_per_sec: 2.1018
	 Train time/train: 9.3231
	 Train time/val: 1.0187
	 Train time/total: 10.3418
[2025-04-11 21:11:23,507] [INFO] [logging.py:96:log_dist] [Rank 0] step=1150, skipped=0, lr=[6.511442786069653e-05], mom=[[0.9, 0.98]]
[2025-04-11 21:11:23,508] [INFO] [timer.py:260:stop] epoch=0/micro_step=36800/global_step=1150, RunningAvgSamplesPerSec=2.2980753063334642, CurrSamplesPerSec=2.2058596410694005, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 21:16:27,503] [INFO] [logging.py:96:log_dist] [Rank 0] step=1160, skipped=0, lr=[6.491542288557215e-05], mom=[[0.9, 0.98]]
[2025-04-11 21:16:27,504] [INFO] [timer.py:260:stop] epoch=0/micro_step=37120/global_step=1160, RunningAvgSamplesPerSec=2.297359638136389, CurrSamplesPerSec=2.184213824515823, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 21:21:30,054] [INFO] [logging.py:96:log_dist] [Rank 0] step=1170, skipped=0, lr=[6.471641791044777e-05], mom=[[0.9, 0.98]]
[2025-04-11 21:21:30,055] [INFO] [timer.py:260:stop] epoch=0/micro_step=37440/global_step=1170, RunningAvgSamplesPerSec=2.296744769294062, CurrSamplesPerSec=2.3136098888621905, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 21:26:33,267] [INFO] [logging.py:96:log_dist] [Rank 0] step=1180, skipped=0, lr=[6.451741293532339e-05], mom=[[0.9, 0.98]]
[2025-04-11 21:26:33,268] [INFO] [timer.py:260:stop] epoch=0/micro_step=37760/global_step=1180, RunningAvgSamplesPerSec=2.2960844540206304, CurrSamplesPerSec=2.1764708267054607, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 21:31:34,758] [INFO] [logging.py:96:log_dist] [Rank 0] step=1190, skipped=0, lr=[6.4318407960199e-05], mom=[[0.9, 0.98]]
[2025-04-11 21:31:34,759] [INFO] [timer.py:260:stop] epoch=0/micro_step=38080/global_step=1190, RunningAvgSamplesPerSec=2.2955780469316607, CurrSamplesPerSec=2.173202121645939, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=3][batch=396/402]:
	 Train time/batch: 1199
	 Train time/sample: 76618
	 Train time/batch_in_epoch: 395
	 Train time/sample_in_epoch: 25280
	 Train time/token: 78187561
	 Train time/token_in_epoch: 25802176
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0418
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 1.0005
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 26.4194
	 Train throughput/batches_per_sec: 0.0329
	 Train throughput/samples_per_sec: 2.1044
	 Train throughput/device/batches_per_sec: 0.0329
	 Train throughput/device/samples_per_sec: 2.1044
	 Train time/train: 9.7440
	 Train time/val: 1.0187
	 Train time/total: 10.7627
[2025-04-11 21:36:39,556] [INFO] [logging.py:96:log_dist] [Rank 0] step=1200, skipped=0, lr=[6.411940298507463e-05], mom=[[0.9, 0.98]]
[2025-04-11 21:36:39,557] [INFO] [timer.py:260:stop] epoch=0/micro_step=38400/global_step=1200, RunningAvgSamplesPerSec=2.2948876805214553, CurrSamplesPerSec=2.1722688708755196, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[Eval batch=1/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on in-domain-standard-q-answer-eval data:
	 Eval metrics/in-domain-standard-q-answer-eval/QA-EM: 0.0092
	 Eval metrics/in-domain-standard-q-answer-eval/QA-F1: 0.1270
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@1-att: 0.0217
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@10-att: 0.0870
[Eval batch=1/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on out-of-domain-standard-q-answer-eval data:
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-EM: 0.0070
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-F1: 0.1274
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@1-att: 0.0000
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@10-att: 0.0286
[2025-04-11 22:07:41,364] [INFO] [logging.py:96:log_dist] [Rank 0] step=1210, skipped=0, lr=[6.390049751243782e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:07:41,365] [INFO] [timer.py:260:stop] epoch=0/micro_step=38720/global_step=1210, RunningAvgSamplesPerSec=2.294095400699405, CurrSamplesPerSec=2.266931400949065, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 22:12:42,291] [INFO] [logging.py:96:log_dist] [Rank 0] step=1220, skipped=0, lr=[6.370149253731343e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:12:42,292] [INFO] [timer.py:260:stop] epoch=0/micro_step=39040/global_step=1220, RunningAvgSamplesPerSec=2.2936337233797794, CurrSamplesPerSec=2.184021435535768, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 22:17:44,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=1230, skipped=0, lr=[6.350248756218906e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:17:44,424] [INFO] [timer.py:260:stop] epoch=0/micro_step=39360/global_step=1230, RunningAvgSamplesPerSec=2.293091403172793, CurrSamplesPerSec=2.234292414565376, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 22:22:51,003] [INFO] [logging.py:96:log_dist] [Rank 0] step=1240, skipped=0, lr=[6.330348258706468e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:22:51,004] [INFO] [timer.py:260:stop] epoch=0/micro_step=39680/global_step=1240, RunningAvgSamplesPerSec=2.2922860147851485, CurrSamplesPerSec=2.1943768851654735, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=4][batch=44/402]:
	 Train time/epoch: 3
	 Train time/batch: 1249
	 Train time/sample: 79759
	 Train time/batch_in_epoch: 43
	 Train time/sample_in_epoch: 2752
	 Train time/token: 81391274
	 Train time/token_in_epoch: 2809664
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0334
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.8973
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 25.5668
	 Train throughput/batches_per_sec: 0.0325
	 Train throughput/samples_per_sec: 2.0809
	 Train throughput/device/batches_per_sec: 0.0325
	 Train throughput/device/samples_per_sec: 2.0809
	 Train time/train: 10.1596
	 Train time/val: 1.4508
	 Train time/total: 11.6104
[2025-04-11 22:27:57,237] [INFO] [logging.py:96:log_dist] [Rank 0] step=1250, skipped=0, lr=[6.310447761194031e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:27:57,239] [INFO] [timer.py:260:stop] epoch=0/micro_step=40000/global_step=1250, RunningAvgSamplesPerSec=2.291501589937755, CurrSamplesPerSec=2.212041112259534, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 22:32:59,323] [INFO] [logging.py:96:log_dist] [Rank 0] step=1260, skipped=0, lr=[6.290547263681592e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:32:59,325] [INFO] [timer.py:260:stop] epoch=0/micro_step=40320/global_step=1260, RunningAvgSamplesPerSec=2.290998638144596, CurrSamplesPerSec=2.202844098438993, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 22:38:04,956] [INFO] [logging.py:96:log_dist] [Rank 0] step=1270, skipped=0, lr=[6.270646766169155e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:38:04,957] [INFO] [timer.py:260:stop] epoch=0/micro_step=40640/global_step=1270, RunningAvgSamplesPerSec=2.2902506575644668, CurrSamplesPerSec=2.203943840517612, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 22:43:00,912] [INFO] [logging.py:96:log_dist] [Rank 0] step=1280, skipped=0, lr=[6.250746268656716e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:43:00,913] [INFO] [timer.py:260:stop] epoch=0/micro_step=40960/global_step=1280, RunningAvgSamplesPerSec=2.2901514035407557, CurrSamplesPerSec=2.1988007912311023, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 22:48:02,899] [INFO] [logging.py:96:log_dist] [Rank 0] step=1290, skipped=0, lr=[6.230845771144279e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:48:02,900] [INFO] [timer.py:260:stop] epoch=0/micro_step=41280/global_step=1290, RunningAvgSamplesPerSec=2.289677938669101, CurrSamplesPerSec=2.169986196539439, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=4][batch=94/402]:
	 Train time/batch: 1299
	 Train time/sample: 82959
	 Train time/batch_in_epoch: 93
	 Train time/sample_in_epoch: 5952
	 Train time/token: 84655146
	 Train time/token_in_epoch: 6073536
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0397
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.8898
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 25.1879
	 Train throughput/batches_per_sec: 0.0330
	 Train throughput/samples_per_sec: 2.1102
	 Train throughput/device/batches_per_sec: 0.0330
	 Train throughput/device/samples_per_sec: 2.1102
	 Train time/train: 10.5791
	 Train time/val: 1.4508
	 Train time/total: 12.0299
[2025-04-11 22:53:07,232] [INFO] [logging.py:96:log_dist] [Rank 0] step=1300, skipped=0, lr=[6.21094527363184e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:53:07,233] [INFO] [timer.py:260:stop] epoch=0/micro_step=41600/global_step=1300, RunningAvgSamplesPerSec=2.289057688552545, CurrSamplesPerSec=2.2468191160302844, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 22:58:13,137] [INFO] [logging.py:96:log_dist] [Rank 0] step=1310, skipped=0, lr=[6.191044776119404e-05], mom=[[0.9, 0.98]]
[2025-04-11 22:58:13,138] [INFO] [timer.py:260:stop] epoch=0/micro_step=41920/global_step=1310, RunningAvgSamplesPerSec=2.2883571194833094, CurrSamplesPerSec=2.2476810432685506, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:03:13,629] [INFO] [logging.py:96:log_dist] [Rank 0] step=1320, skipped=0, lr=[6.171144278606966e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:03:13,630] [INFO] [timer.py:260:stop] epoch=0/micro_step=42240/global_step=1320, RunningAvgSamplesPerSec=2.2880172511491654, CurrSamplesPerSec=2.208235237927061, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:08:18,474] [INFO] [logging.py:96:log_dist] [Rank 0] step=1330, skipped=0, lr=[6.151243781094527e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:08:18,475] [INFO] [timer.py:260:stop] epoch=0/micro_step=42560/global_step=1330, RunningAvgSamplesPerSec=2.2873949865698178, CurrSamplesPerSec=2.299005234325048, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:13:24,686] [INFO] [logging.py:96:log_dist] [Rank 0] step=1340, skipped=0, lr=[6.13134328358209e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:13:24,688] [INFO] [timer.py:260:stop] epoch=0/micro_step=42880/global_step=1340, RunningAvgSamplesPerSec=2.286704459532574, CurrSamplesPerSec=2.1650524248929077, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=4][batch=144/402]:
	 Train time/batch: 1349
	 Train time/sample: 86159
	 Train time/batch_in_epoch: 143
	 Train time/sample_in_epoch: 9152
	 Train time/token: 87920298
	 Train time/token_in_epoch: 9338688
	 Train memory/allocated_mem: 3.3474
	 Train memory/active_mem: 3.3474
	 Train memory/inactive_mem: 0.0416
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.8950
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 24.8084
	 Train throughput/batches_per_sec: 0.0334
	 Train throughput/samples_per_sec: 2.1365
	 Train throughput/device/batches_per_sec: 0.0334
	 Train throughput/device/samples_per_sec: 2.1365
	 Train time/train: 10.9998
	 Train time/val: 1.4508
	 Train time/total: 12.4506
[2025-04-11 23:18:24,567] [INFO] [logging.py:96:log_dist] [Rank 0] step=1350, skipped=0, lr=[6.111442786069652e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:18:24,568] [INFO] [timer.py:260:stop] epoch=0/micro_step=43200/global_step=1350, RunningAvgSamplesPerSec=2.286411622698919, CurrSamplesPerSec=2.173116231968331, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:23:28,272] [INFO] [logging.py:96:log_dist] [Rank 0] step=1360, skipped=0, lr=[6.091542288557214e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:23:28,273] [INFO] [timer.py:260:stop] epoch=0/micro_step=43520/global_step=1360, RunningAvgSamplesPerSec=2.2858976312723804, CurrSamplesPerSec=2.1625112674995672, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:28:33,220] [INFO] [logging.py:96:log_dist] [Rank 0] step=1370, skipped=0, lr=[6.071641791044776e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:28:33,222] [INFO] [timer.py:260:stop] epoch=0/micro_step=43840/global_step=1370, RunningAvgSamplesPerSec=2.285328487601662, CurrSamplesPerSec=2.1368536898242594, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:33:37,524] [INFO] [logging.py:96:log_dist] [Rank 0] step=1380, skipped=0, lr=[6.051741293532338e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:33:37,526] [INFO] [timer.py:260:stop] epoch=0/micro_step=44160/global_step=1380, RunningAvgSamplesPerSec=2.2847839715322635, CurrSamplesPerSec=2.183805007350169, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:38:46,642] [INFO] [logging.py:96:log_dist] [Rank 0] step=1390, skipped=0, lr=[6.031840796019901e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:38:46,643] [INFO] [timer.py:260:stop] epoch=0/micro_step=44480/global_step=1390, RunningAvgSamplesPerSec=2.2839789826813197, CurrSamplesPerSec=2.1680170239545546, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=4][batch=194/402]:
	 Train time/batch: 1399
	 Train time/sample: 89359
	 Train time/batch_in_epoch: 193
	 Train time/sample_in_epoch: 12352
	 Train time/token: 91187434
	 Train time/token_in_epoch: 12605824
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0334
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.9502
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 24.4329
	 Train throughput/batches_per_sec: 0.0328
	 Train throughput/samples_per_sec: 2.1013
	 Train throughput/device/batches_per_sec: 0.0328
	 Train throughput/device/samples_per_sec: 2.1013
	 Train time/train: 11.4243
	 Train time/val: 1.4508
	 Train time/total: 12.8750
[2025-04-11 23:43:50,420] [INFO] [logging.py:96:log_dist] [Rank 0] step=1400, skipped=0, lr=[6.011940298507463e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:43:50,422] [INFO] [timer.py:260:stop] epoch=0/micro_step=44800/global_step=1400, RunningAvgSamplesPerSec=2.2834744291615006, CurrSamplesPerSec=2.2340805789679044, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:48:55,872] [INFO] [logging.py:96:log_dist] [Rank 0] step=1410, skipped=0, lr=[5.9920398009950256e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:48:55,873] [INFO] [timer.py:260:stop] epoch=0/micro_step=45120/global_step=1410, RunningAvgSamplesPerSec=2.2829015781440263, CurrSamplesPerSec=2.160090749810013, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:54:04,488] [INFO] [logging.py:96:log_dist] [Rank 0] step=1420, skipped=0, lr=[5.9721393034825876e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:54:04,490] [INFO] [timer.py:260:stop] epoch=0/micro_step=45440/global_step=1420, RunningAvgSamplesPerSec=2.2821615094359413, CurrSamplesPerSec=2.173637462568109, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-11 23:59:02,655] [INFO] [logging.py:96:log_dist] [Rank 0] step=1430, skipped=0, lr=[5.952238805970149e-05], mom=[[0.9, 0.98]]
[2025-04-11 23:59:02,656] [INFO] [timer.py:260:stop] epoch=0/micro_step=45760/global_step=1430, RunningAvgSamplesPerSec=2.281997383728549, CurrSamplesPerSec=2.3142739850725076, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 00:04:04,610] [INFO] [logging.py:96:log_dist] [Rank 0] step=1440, skipped=0, lr=[5.932338308457711e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:04:04,611] [INFO] [timer.py:260:stop] epoch=0/micro_step=46080/global_step=1440, RunningAvgSamplesPerSec=2.2816432859307643, CurrSamplesPerSec=2.187054461788023, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=4][batch=244/402]:
	 Train time/batch: 1449
	 Train time/sample: 92559
	 Train time/batch_in_epoch: 243
	 Train time/sample_in_epoch: 15552
	 Train time/token: 94453034
	 Train time/token_in_epoch: 15871424
	 Train memory/allocated_mem: 3.3471
	 Train memory/active_mem: 3.3471
	 Train memory/inactive_mem: 0.0335
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.9171
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 24.0501
	 Train throughput/batches_per_sec: 0.0325
	 Train throughput/samples_per_sec: 2.0829
	 Train throughput/device/batches_per_sec: 0.0325
	 Train throughput/device/samples_per_sec: 2.0829
	 Train time/train: 11.8465
	 Train time/val: 1.4508
	 Train time/total: 13.2972
[2025-04-12 00:09:13,075] [INFO] [logging.py:96:log_dist] [Rank 0] step=1450, skipped=0, lr=[5.9124378109452736e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:09:13,076] [INFO] [timer.py:260:stop] epoch=0/micro_step=46400/global_step=1450, RunningAvgSamplesPerSec=2.280924876195149, CurrSamplesPerSec=2.1415964849267954, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 00:14:23,597] [INFO] [logging.py:96:log_dist] [Rank 0] step=1460, skipped=0, lr=[5.892537313432836e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:14:23,598] [INFO] [timer.py:260:stop] epoch=0/micro_step=46720/global_step=1460, RunningAvgSamplesPerSec=2.28008086285536, CurrSamplesPerSec=2.1541006661246174, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 00:19:26,716] [INFO] [logging.py:96:log_dist] [Rank 0] step=1470, skipped=0, lr=[5.872636815920398e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:19:26,717] [INFO] [timer.py:260:stop] epoch=0/micro_step=47040/global_step=1470, RunningAvgSamplesPerSec=2.2797056222942267, CurrSamplesPerSec=2.2963784180198235, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 00:24:25,648] [INFO] [logging.py:96:log_dist] [Rank 0] step=1480, skipped=0, lr=[5.85273631840796e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:24:25,649] [INFO] [timer.py:260:stop] epoch=0/micro_step=47360/global_step=1480, RunningAvgSamplesPerSec=2.2795252073396446, CurrSamplesPerSec=2.287653250392369, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 00:29:30,871] [INFO] [logging.py:96:log_dist] [Rank 0] step=1490, skipped=0, lr=[5.832835820895522e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:29:30,872] [INFO] [timer.py:260:stop] epoch=0/micro_step=47680/global_step=1490, RunningAvgSamplesPerSec=2.279067735146941, CurrSamplesPerSec=2.2359973936245425, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=4][batch=294/402]:
	 Train time/batch: 1499
	 Train time/sample: 95759
	 Train time/batch_in_epoch: 293
	 Train time/sample_in_epoch: 18752
	 Train time/token: 97717162
	 Train time/token_in_epoch: 19135552
	 Train memory/allocated_mem: 3.3467
	 Train memory/active_mem: 3.3467
	 Train memory/inactive_mem: 0.0381
	 Train memory/reserved_mem: 33.3470
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.8291
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 23.6654
	 Train throughput/batches_per_sec: 0.0329
	 Train throughput/samples_per_sec: 2.1059
	 Train throughput/device/batches_per_sec: 0.0329
	 Train throughput/device/samples_per_sec: 2.1059
	 Train time/train: 12.2691
	 Train time/val: 1.4508
	 Train time/total: 13.7198
[2025-04-12 00:34:34,281] [INFO] [logging.py:96:log_dist] [Rank 0] step=1500, skipped=0, lr=[5.812935323383085e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:34:34,283] [INFO] [timer.py:260:stop] epoch=0/micro_step=48000/global_step=1500, RunningAvgSamplesPerSec=2.2786727147758365, CurrSamplesPerSec=2.186590522111656, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 00:39:35,600] [INFO] [logging.py:96:log_dist] [Rank 0] step=1510, skipped=0, lr=[5.7930348258706476e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:39:35,601] [INFO] [timer.py:260:stop] epoch=0/micro_step=48320/global_step=1510, RunningAvgSamplesPerSec=2.278413315264065, CurrSamplesPerSec=2.1805113475019797, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 00:44:34,796] [INFO] [logging.py:96:log_dist] [Rank 0] step=1520, skipped=0, lr=[5.7731343283582096e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:44:34,797] [INFO] [timer.py:260:stop] epoch=0/micro_step=48640/global_step=1520, RunningAvgSamplesPerSec=2.278215730834612, CurrSamplesPerSec=2.1863596589126715, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 00:49:31,424] [INFO] [logging.py:96:log_dist] [Rank 0] step=1530, skipped=0, lr=[5.753233830845771e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:49:31,425] [INFO] [timer.py:260:stop] epoch=0/micro_step=48960/global_step=1530, RunningAvgSamplesPerSec=2.2781382285779412, CurrSamplesPerSec=2.224895228652799, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 00:54:23,670] [INFO] [logging.py:96:log_dist] [Rank 0] step=1540, skipped=0, lr=[5.7333333333333336e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:54:23,670] [INFO] [timer.py:260:stop] epoch=0/micro_step=49280/global_step=1540, RunningAvgSamplesPerSec=2.2783182666363175, CurrSamplesPerSec=2.434787656509682, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=4][batch=344/402]:
	 Train time/batch: 1549
	 Train time/sample: 98959
	 Train time/batch_in_epoch: 343
	 Train time/sample_in_epoch: 21952
	 Train time/token: 100979178
	 Train time/token_in_epoch: 22397568
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0459
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.8978
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 23.2641
	 Train throughput/batches_per_sec: 0.0339
	 Train throughput/samples_per_sec: 2.1689
	 Train throughput/device/batches_per_sec: 0.0339
	 Train throughput/device/samples_per_sec: 2.1689
	 Train time/train: 12.6828
	 Train time/val: 1.4508
	 Train time/total: 14.1336
[2025-04-12 00:59:18,189] [INFO] [logging.py:96:log_dist] [Rank 0] step=1550, skipped=0, lr=[5.713432835820897e-05], mom=[[0.9, 0.98]]
[2025-04-12 00:59:18,189] [INFO] [timer.py:260:stop] epoch=0/micro_step=49600/global_step=1550, RunningAvgSamplesPerSec=2.278354003809156, CurrSamplesPerSec=2.289987910222014, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 01:04:28,946] [INFO] [logging.py:96:log_dist] [Rank 0] step=1560, skipped=0, lr=[5.693532338308458e-05], mom=[[0.9, 0.98]]
[2025-04-12 01:04:28,948] [INFO] [timer.py:260:stop] epoch=0/micro_step=49920/global_step=1560, RunningAvgSamplesPerSec=2.2775796121403373, CurrSamplesPerSec=2.1800812341710176, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 01:09:32,970] [INFO] [logging.py:96:log_dist] [Rank 0] step=1570, skipped=0, lr=[5.67363184079602e-05], mom=[[0.9, 0.98]]
[2025-04-12 01:09:32,971] [INFO] [timer.py:260:stop] epoch=0/micro_step=50240/global_step=1570, RunningAvgSamplesPerSec=2.277180894298272, CurrSamplesPerSec=2.1298359128198117, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 01:14:35,587] [INFO] [logging.py:96:log_dist] [Rank 0] step=1580, skipped=0, lr=[5.653731343283582e-05], mom=[[0.9, 0.98]]
[2025-04-12 01:14:35,588] [INFO] [timer.py:260:stop] epoch=0/micro_step=50560/global_step=1580, RunningAvgSamplesPerSec=2.276849243685223, CurrSamplesPerSec=2.193703703918602, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 01:19:41,542] [INFO] [logging.py:96:log_dist] [Rank 0] step=1590, skipped=0, lr=[5.633830845771145e-05], mom=[[0.9, 0.98]]
[2025-04-12 01:19:41,543] [INFO] [timer.py:260:stop] epoch=0/micro_step=50880/global_step=1590, RunningAvgSamplesPerSec=2.27639116316404, CurrSamplesPerSec=2.160442535400622, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=4][batch=394/402]:
	 Train time/batch: 1599
	 Train time/sample: 102159
	 Train time/batch_in_epoch: 393
	 Train time/sample_in_epoch: 25152
	 Train time/token: 104245610
	 Train time/token_in_epoch: 25664000
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0480
	 Train memory/reserved_mem: 33.2230
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.9192
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 22.8761
	 Train throughput/batches_per_sec: 0.0329
	 Train throughput/samples_per_sec: 2.1057
	 Train throughput/device/batches_per_sec: 0.0329
	 Train throughput/device/samples_per_sec: 2.1057
	 Train time/train: 13.1059
	 Train time/val: 1.4508
	 Train time/total: 14.5567
[2025-04-12 01:24:47,940] [INFO] [logging.py:96:log_dist] [Rank 0] step=1600, skipped=0, lr=[5.6139303482587075e-05], mom=[[0.9, 0.98]]
[2025-04-12 01:24:47,941] [INFO] [timer.py:260:stop] epoch=0/micro_step=51200/global_step=1600, RunningAvgSamplesPerSec=2.275922303954977, CurrSamplesPerSec=2.128484590213236, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[Eval batch=1/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on in-domain-standard-q-answer-eval data:
	 Eval metrics/in-domain-standard-q-answer-eval/QA-EM: 0.0072
	 Eval metrics/in-domain-standard-q-answer-eval/QA-F1: 0.1271
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@1-att: 0.4167
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@10-att: 0.5278
[Eval batch=1/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on out-of-domain-standard-q-answer-eval data:
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-EM: 0.0084
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-F1: 0.1299
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@1-att: 0.0000
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@10-att: 0.0000
[2025-04-12 01:54:09,511] [INFO] [logging.py:96:log_dist] [Rank 0] step=1610, skipped=0, lr=[5.5920398009950254e-05], mom=[[0.9, 0.98]]
[2025-04-12 01:54:09,512] [INFO] [timer.py:260:stop] epoch=0/micro_step=51520/global_step=1610, RunningAvgSamplesPerSec=2.2756139187930913, CurrSamplesPerSec=2.159721702387693, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 01:59:10,056] [INFO] [logging.py:96:log_dist] [Rank 0] step=1620, skipped=0, lr=[5.572139303482587e-05], mom=[[0.9, 0.98]]
[2025-04-12 01:59:10,057] [INFO] [timer.py:260:stop] epoch=0/micro_step=51840/global_step=1620, RunningAvgSamplesPerSec=2.275368265005695, CurrSamplesPerSec=2.1461996025322003, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 02:04:10,336] [INFO] [logging.py:96:log_dist] [Rank 0] step=1630, skipped=0, lr=[5.55223880597015e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:04:10,337] [INFO] [timer.py:260:stop] epoch=0/micro_step=52160/global_step=1630, RunningAvgSamplesPerSec=2.275126250276049, CurrSamplesPerSec=2.1798618864722616, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 02:09:08,035] [INFO] [logging.py:96:log_dist] [Rank 0] step=1640, skipped=0, lr=[5.532338308457713e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:09:08,036] [INFO] [timer.py:260:stop] epoch=0/micro_step=52480/global_step=1640, RunningAvgSamplesPerSec=2.2750346597033393, CurrSamplesPerSec=2.2131832498601853, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=5][batch=42/402]:
	 Train time/epoch: 4
	 Train time/batch: 1649
	 Train time/sample: 105300
	 Train time/batch_in_epoch: 41
	 Train time/sample_in_epoch: 2624
	 Train time/token: 107448784
	 Train time/token_in_epoch: 2675328
	 Train memory/allocated_mem: 3.3474
	 Train memory/active_mem: 3.3474
	 Train memory/inactive_mem: 0.0416
	 Train memory/reserved_mem: 33.2610
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.7268
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 21.9713
	 Train throughput/batches_per_sec: 0.0328
	 Train throughput/samples_per_sec: 2.0985
	 Train throughput/device/batches_per_sec: 0.0328
	 Train throughput/device/samples_per_sec: 2.0985
	 Train time/train: 13.5175
	 Train time/val: 1.8559
	 Train time/total: 15.3734
[2025-04-12 02:14:14,930] [INFO] [logging.py:96:log_dist] [Rank 0] step=1650, skipped=0, lr=[5.512437810945274e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:14:14,931] [INFO] [timer.py:260:stop] epoch=0/micro_step=52800/global_step=1650, RunningAvgSamplesPerSec=2.2745236216194042, CurrSamplesPerSec=2.1446243833011978, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 02:19:09,606] [INFO] [logging.py:96:log_dist] [Rank 0] step=1660, skipped=0, lr=[5.492537313432836e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:19:09,607] [INFO] [timer.py:260:stop] epoch=0/micro_step=53120/global_step=1660, RunningAvgSamplesPerSec=2.274574022449825, CurrSamplesPerSec=2.2520269928343324, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 02:24:10,737] [INFO] [logging.py:96:log_dist] [Rank 0] step=1670, skipped=0, lr=[5.472636815920398e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:24:10,739] [INFO] [timer.py:260:stop] epoch=0/micro_step=53440/global_step=1670, RunningAvgSamplesPerSec=2.2743222615258367, CurrSamplesPerSec=2.21634363624162, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 02:29:04,192] [INFO] [logging.py:96:log_dist] [Rank 0] step=1680, skipped=0, lr=[5.452736318407961e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:29:04,193] [INFO] [timer.py:260:stop] epoch=0/micro_step=53760/global_step=1680, RunningAvgSamplesPerSec=2.274407365936164, CurrSamplesPerSec=2.15457412737749, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 02:34:07,736] [INFO] [logging.py:96:log_dist] [Rank 0] step=1690, skipped=0, lr=[5.4328358208955234e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:34:07,737] [INFO] [timer.py:260:stop] epoch=0/micro_step=54080/global_step=1690, RunningAvgSamplesPerSec=2.274010777812292, CurrSamplesPerSec=2.1465218688253667, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=5][batch=92/402]:
	 Train time/batch: 1699
	 Train time/sample: 108500
	 Train time/batch_in_epoch: 91
	 Train time/sample_in_epoch: 5824
	 Train time/token: 110714128
	 Train time/token_in_epoch: 5940672
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0376
	 Train memory/reserved_mem: 33.2610
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.7323
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 21.5710
	 Train throughput/batches_per_sec: 0.0328
	 Train throughput/samples_per_sec: 2.0992
	 Train throughput/device/batches_per_sec: 0.0328
	 Train throughput/device/samples_per_sec: 2.0992
	 Train time/train: 13.9339
	 Train time/val: 1.8559
	 Train time/total: 15.7899
[2025-04-12 02:39:08,860] [INFO] [logging.py:96:log_dist] [Rank 0] step=1700, skipped=0, lr=[5.4129353233830854e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:39:08,861] [INFO] [timer.py:260:stop] epoch=0/micro_step=54400/global_step=1700, RunningAvgSamplesPerSec=2.2737757342645706, CurrSamplesPerSec=2.1590896704325955, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 02:44:13,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=1710, skipped=0, lr=[5.3930348258706473e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:44:13,405] [INFO] [timer.py:260:stop] epoch=0/micro_step=54720/global_step=1710, RunningAvgSamplesPerSec=2.2733612009071837, CurrSamplesPerSec=2.1575112251115347, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 02:49:07,147] [INFO] [logging.py:96:log_dist] [Rank 0] step=1720, skipped=0, lr=[5.3731343283582087e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:49:07,148] [INFO] [timer.py:260:stop] epoch=0/micro_step=55040/global_step=1720, RunningAvgSamplesPerSec=2.273478176754184, CurrSamplesPerSec=2.450620704328748, MemAllocated=3.58GB, MaxMemAllocated=17.36GB
[2025-04-12 02:54:02,923] [INFO] [logging.py:96:log_dist] [Rank 0] step=1730, skipped=0, lr=[5.353233830845771e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:54:02,924] [INFO] [timer.py:260:stop] epoch=0/micro_step=55360/global_step=1730, RunningAvgSamplesPerSec=2.273435078556719, CurrSamplesPerSec=2.241270565095125, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 02:59:03,126] [INFO] [logging.py:96:log_dist] [Rank 0] step=1740, skipped=0, lr=[5.333333333333335e-05], mom=[[0.9, 0.98]]
[2025-04-12 02:59:03,127] [INFO] [timer.py:260:stop] epoch=0/micro_step=55680/global_step=1740, RunningAvgSamplesPerSec=2.273218941326892, CurrSamplesPerSec=2.1721286368911965, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=5][batch=142/402]:
	 Train time/batch: 1749
	 Train time/sample: 111700
	 Train time/batch_in_epoch: 141
	 Train time/sample_in_epoch: 9024
	 Train time/token: 113975696
	 Train time/token_in_epoch: 9202240
	 Train memory/allocated_mem: 3.3490
	 Train memory/active_mem: 3.3490
	 Train memory/inactive_mem: 0.0358
	 Train memory/reserved_mem: 33.3200
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.6983
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 21.1679
	 Train throughput/batches_per_sec: 0.0331
	 Train throughput/samples_per_sec: 2.1200
	 Train throughput/device/batches_per_sec: 0.0331
	 Train throughput/device/samples_per_sec: 2.1200
	 Train time/train: 14.3489
	 Train time/val: 1.8559
	 Train time/total: 16.2049
[2025-04-12 03:04:05,763] [INFO] [logging.py:96:log_dist] [Rank 0] step=1750, skipped=0, lr=[5.313432835820896e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:04:05,764] [INFO] [timer.py:260:stop] epoch=0/micro_step=56000/global_step=1750, RunningAvgSamplesPerSec=2.2728963168896072, CurrSamplesPerSec=2.1530646844789665, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 03:09:12,271] [INFO] [logging.py:96:log_dist] [Rank 0] step=1760, skipped=0, lr=[5.293532338308458e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:09:12,272] [INFO] [timer.py:260:stop] epoch=0/micro_step=56320/global_step=1760, RunningAvgSamplesPerSec=2.2724701697824807, CurrSamplesPerSec=2.184273364274475, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 03:14:08,963] [INFO] [logging.py:96:log_dist] [Rank 0] step=1770, skipped=0, lr=[5.27363184079602e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:14:08,964] [INFO] [timer.py:260:stop] epoch=0/micro_step=56640/global_step=1770, RunningAvgSamplesPerSec=2.272473934733784, CurrSamplesPerSec=2.3019108352898923, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 03:19:01,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=1780, skipped=0, lr=[5.2537313432835826e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:19:01,636] [INFO] [timer.py:260:stop] epoch=0/micro_step=56960/global_step=1780, RunningAvgSamplesPerSec=2.2726163817019063, CurrSamplesPerSec=2.293267918789023, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 03:24:02,431] [INFO] [logging.py:96:log_dist] [Rank 0] step=1790, skipped=0, lr=[5.2338308457711446e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:24:02,432] [INFO] [timer.py:260:stop] epoch=0/micro_step=57280/global_step=1790, RunningAvgSamplesPerSec=2.272412096449826, CurrSamplesPerSec=2.125860264738072, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=5][batch=192/402]:
	 Train time/batch: 1799
	 Train time/sample: 114900
	 Train time/batch_in_epoch: 191
	 Train time/sample_in_epoch: 12224
	 Train time/token: 117240784
	 Train time/token_in_epoch: 12467328
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0438
	 Train memory/reserved_mem: 33.1940
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.7477
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 20.7636
	 Train throughput/batches_per_sec: 0.0337
	 Train throughput/samples_per_sec: 2.1564
	 Train throughput/device/batches_per_sec: 0.0337
	 Train throughput/device/samples_per_sec: 2.1564
	 Train time/train: 14.7635
	 Train time/val: 1.8559
	 Train time/total: 16.6194
[2025-04-12 03:28:53,712] [INFO] [logging.py:96:log_dist] [Rank 0] step=1800, skipped=0, lr=[5.213930348258707e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:28:53,713] [INFO] [timer.py:260:stop] epoch=0/micro_step=57600/global_step=1800, RunningAvgSamplesPerSec=2.2726627420973227, CurrSamplesPerSec=2.380827778624892, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 03:33:51,807] [INFO] [logging.py:96:log_dist] [Rank 0] step=1810, skipped=0, lr=[5.194029850746269e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:33:51,808] [INFO] [timer.py:260:stop] epoch=0/micro_step=57920/global_step=1810, RunningAvgSamplesPerSec=2.2725734195495173, CurrSamplesPerSec=2.3074505361143998, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 03:38:44,109] [INFO] [logging.py:96:log_dist] [Rank 0] step=1820, skipped=0, lr=[5.1741293532338306e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:38:44,110] [INFO] [timer.py:260:stop] epoch=0/micro_step=58240/global_step=1820, RunningAvgSamplesPerSec=2.2727632569610625, CurrSamplesPerSec=2.2441976885041344, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 03:43:47,706] [INFO] [logging.py:96:log_dist] [Rank 0] step=1830, skipped=0, lr=[5.154228855721393e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:43:47,707] [INFO] [timer.py:260:stop] epoch=0/micro_step=58560/global_step=1830, RunningAvgSamplesPerSec=2.2724792881204774, CurrSamplesPerSec=2.2947566700786832, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 03:48:44,394] [INFO] [logging.py:96:log_dist] [Rank 0] step=1840, skipped=0, lr=[5.134328358208955e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:48:44,395] [INFO] [timer.py:260:stop] epoch=0/micro_step=58880/global_step=1840, RunningAvgSamplesPerSec=2.272463393536511, CurrSamplesPerSec=2.433883223689922, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=5][batch=242/402]:
	 Train time/batch: 1849
	 Train time/sample: 118100
	 Train time/batch_in_epoch: 241
	 Train time/sample_in_epoch: 15424
	 Train time/token: 120506192
	 Train time/token_in_epoch: 15732736
	 Train memory/allocated_mem: 3.3490
	 Train memory/active_mem: 3.3490
	 Train memory/inactive_mem: 0.0400
	 Train memory/reserved_mem: 33.3200
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.7479
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 20.3556
	 Train throughput/batches_per_sec: 0.0343
	 Train throughput/samples_per_sec: 2.1962
	 Train throughput/device/batches_per_sec: 0.0343
	 Train throughput/device/samples_per_sec: 2.1962
	 Train time/train: 15.1754
	 Train time/val: 1.8559
	 Train time/total: 17.0313
[2025-04-12 03:53:37,846] [INFO] [logging.py:96:log_dist] [Rank 0] step=1850, skipped=0, lr=[5.114427860696518e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:53:37,847] [INFO] [timer.py:260:stop] epoch=0/micro_step=59200/global_step=1850, RunningAvgSamplesPerSec=2.272544663522094, CurrSamplesPerSec=2.299153547034554, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 03:58:38,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=1860, skipped=0, lr=[5.09452736318408e-05], mom=[[0.9, 0.98]]
[2025-04-12 03:58:38,702] [INFO] [timer.py:260:stop] epoch=0/micro_step=59520/global_step=1860, RunningAvgSamplesPerSec=2.2723479369151334, CurrSamplesPerSec=2.1733247399570583, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:03:36,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=1870, skipped=0, lr=[5.074626865671642e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:03:36,269] [INFO] [timer.py:260:stop] epoch=0/micro_step=59840/global_step=1870, RunningAvgSamplesPerSec=2.272275279313364, CurrSamplesPerSec=2.1954597477183975, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:08:37,397] [INFO] [logging.py:96:log_dist] [Rank 0] step=1880, skipped=0, lr=[5.054726368159204e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:08:37,398] [INFO] [timer.py:260:stop] epoch=0/micro_step=60160/global_step=1880, RunningAvgSamplesPerSec=2.2720839175775893, CurrSamplesPerSec=2.1966547092728113, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:13:40,113] [INFO] [logging.py:96:log_dist] [Rank 0] step=1890, skipped=0, lr=[5.0348258706467666e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:13:40,114] [INFO] [timer.py:260:stop] epoch=0/micro_step=60480/global_step=1890, RunningAvgSamplesPerSec=2.271839483273326, CurrSamplesPerSec=2.1696455883263654, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=5][batch=292/402]:
	 Train time/batch: 1899
	 Train time/sample: 121300
	 Train time/batch_in_epoch: 291
	 Train time/sample_in_epoch: 18624
	 Train time/token: 123773456
	 Train time/token_in_epoch: 19000000
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0375
	 Train memory/reserved_mem: 33.1940
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.7074
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0001
	 Train time/remaining_estimate: 19.9533
	 Train throughput/batches_per_sec: 0.0330
	 Train throughput/samples_per_sec: 2.1125
	 Train throughput/device/batches_per_sec: 0.0330
	 Train throughput/device/samples_per_sec: 2.1125
	 Train time/train: 15.5925
	 Train time/val: 1.8559
	 Train time/total: 17.4484
[2025-04-12 04:18:39,481] [INFO] [logging.py:96:log_dist] [Rank 0] step=1900, skipped=0, lr=[5.014925373134329e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:18:39,482] [INFO] [timer.py:260:stop] epoch=0/micro_step=60800/global_step=1900, RunningAvgSamplesPerSec=2.2717055329321933, CurrSamplesPerSec=2.4920202617562355, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:23:43,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=1910, skipped=0, lr=[4.9950248756218906e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:23:43,018] [INFO] [timer.py:260:stop] epoch=0/micro_step=61120/global_step=1910, RunningAvgSamplesPerSec=2.2714231962275226, CurrSamplesPerSec=2.2567524797227434, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:28:42,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=1920, skipped=0, lr=[4.9751243781094526e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:28:42,201] [INFO] [timer.py:260:stop] epoch=0/micro_step=61440/global_step=1920, RunningAvgSamplesPerSec=2.2713564402114343, CurrSamplesPerSec=2.156701822931574, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:33:46,692] [INFO] [logging.py:96:log_dist] [Rank 0] step=1930, skipped=0, lr=[4.9552238805970146e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:33:46,693] [INFO] [timer.py:260:stop] epoch=0/micro_step=61760/global_step=1930, RunningAvgSamplesPerSec=2.2710497197248376, CurrSamplesPerSec=2.1632590502160123, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:38:44,790] [INFO] [logging.py:96:log_dist] [Rank 0] step=1940, skipped=0, lr=[4.935323383084577e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:38:44,791] [INFO] [timer.py:260:stop] epoch=0/micro_step=62080/global_step=1940, RunningAvgSamplesPerSec=2.2709832899295708, CurrSamplesPerSec=2.3262625649791016, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=5][batch=342/402]:
	 Train time/batch: 1949
	 Train time/sample: 124500
	 Train time/batch_in_epoch: 341
	 Train time/sample_in_epoch: 21824
	 Train time/token: 127038480
	 Train time/token_in_epoch: 22265024
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0375
	 Train memory/reserved_mem: 33.1940
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.7209
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 19.5504
	 Train throughput/batches_per_sec: 0.0339
	 Train throughput/samples_per_sec: 2.1671
	 Train throughput/device/batches_per_sec: 0.0339
	 Train throughput/device/samples_per_sec: 2.1671
	 Train time/train: 16.0099
	 Train time/val: 1.8559
	 Train time/total: 17.8658
[2025-04-12 04:43:46,019] [INFO] [logging.py:96:log_dist] [Rank 0] step=1950, skipped=0, lr=[4.91542288557214e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:43:46,020] [INFO] [timer.py:260:stop] epoch=0/micro_step=62400/global_step=1950, RunningAvgSamplesPerSec=2.270820721441259, CurrSamplesPerSec=2.1920384963883506, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:48:42,861] [INFO] [logging.py:96:log_dist] [Rank 0] step=1960, skipped=0, lr=[4.895522388059702e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:48:42,862] [INFO] [timer.py:260:stop] epoch=0/micro_step=62720/global_step=1960, RunningAvgSamplesPerSec=2.2707780343310873, CurrSamplesPerSec=2.2515956852475973, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:53:38,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=1970, skipped=0, lr=[4.875621890547264e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:53:38,987] [INFO] [timer.py:260:stop] epoch=0/micro_step=63040/global_step=1970, RunningAvgSamplesPerSec=2.2708070859740657, CurrSamplesPerSec=2.2677745563130505, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 04:58:33,156] [INFO] [logging.py:96:log_dist] [Rank 0] step=1980, skipped=0, lr=[4.855721393034825e-05], mom=[[0.9, 0.98]]
[2025-04-12 04:58:33,157] [INFO] [timer.py:260:stop] epoch=0/micro_step=63360/global_step=1980, RunningAvgSamplesPerSec=2.270918370700572, CurrSamplesPerSec=2.4221375352025265, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 05:03:34,010] [INFO] [logging.py:96:log_dist] [Rank 0] step=1990, skipped=0, lr=[4.8358208955223885e-05], mom=[[0.9, 0.98]]
[2025-04-12 05:03:34,011] [INFO] [timer.py:260:stop] epoch=0/micro_step=63680/global_step=1990, RunningAvgSamplesPerSec=2.2707215461194186, CurrSamplesPerSec=2.27089234966612, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=5][batch=392/402]:
	 Train time/batch: 1999
	 Train time/sample: 127700
	 Train time/batch_in_epoch: 391
	 Train time/sample_in_epoch: 25024
	 Train time/token: 130303632
	 Train time/token_in_epoch: 25530176
	 Train memory/allocated_mem: 3.3474
	 Train memory/active_mem: 3.3474
	 Train memory/inactive_mem: 0.0374
	 Train memory/reserved_mem: 33.1940
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.7794
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 19.1437
	 Train throughput/batches_per_sec: 0.0333
	 Train throughput/samples_per_sec: 2.1314
	 Train throughput/device/batches_per_sec: 0.0333
	 Train throughput/device/samples_per_sec: 2.1314
	 Train time/train: 16.4241
	 Train time/val: 1.8559
	 Train time/total: 18.2801
[2025-04-12 05:08:33,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=2000, skipped=0, lr=[4.815920398009951e-05], mom=[[0.9, 0.98]]
[2025-04-12 05:08:33,186] [INFO] [timer.py:260:stop] epoch=0/micro_step=64000/global_step=2000, RunningAvgSamplesPerSec=2.270619526643056, CurrSamplesPerSec=2.2521127526868776, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[Eval batch=1/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on in-domain-standard-q-answer-eval data:
	 Eval metrics/in-domain-standard-q-answer-eval/QA-EM: 0.0146
	 Eval metrics/in-domain-standard-q-answer-eval/QA-F1: 0.1396
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@1-att: 0.3288
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@10-att: 0.5616
[Eval batch=1/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on out-of-domain-standard-q-answer-eval data:
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-EM: 0.0180
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-F1: 0.1428
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@1-att: 0.0000
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@10-att: 0.0111
[2025-04-12 05:38:22,170] [INFO] [logging.py:96:log_dist] [Rank 0] step=2010, skipped=0, lr=[4.7940298507462684e-05], mom=[[0.9, 0.98]]
[2025-04-12 05:38:22,171] [INFO] [timer.py:260:stop] epoch=0/micro_step=64320/global_step=2010, RunningAvgSamplesPerSec=2.270486420095122, CurrSamplesPerSec=2.3451803639696966, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 05:43:25,001] [INFO] [logging.py:96:log_dist] [Rank 0] step=2020, skipped=0, lr=[4.7741293532338304e-05], mom=[[0.9, 0.98]]
[2025-04-12 05:43:25,002] [INFO] [timer.py:260:stop] epoch=0/micro_step=64640/global_step=2020, RunningAvgSamplesPerSec=2.2702346465541656, CurrSamplesPerSec=2.1797572205984697, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 05:48:23,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=2030, skipped=0, lr=[4.754228855721393e-05], mom=[[0.9, 0.98]]
[2025-04-12 05:48:23,533] [INFO] [timer.py:260:stop] epoch=0/micro_step=64960/global_step=2030, RunningAvgSamplesPerSec=2.270146774167694, CurrSamplesPerSec=2.229598901540985, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 05:53:24,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=2040, skipped=0, lr=[4.734328358208956e-05], mom=[[0.9, 0.98]]
[2025-04-12 05:53:24,863] [INFO] [timer.py:260:stop] epoch=0/micro_step=65280/global_step=2040, RunningAvgSamplesPerSec=2.2699751308194633, CurrSamplesPerSec=2.187236549807505, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=6][batch=40/402]:
	 Train time/epoch: 5
	 Train time/batch: 2049
	 Train time/sample: 130841
	 Train time/batch_in_epoch: 39
	 Train time/sample_in_epoch: 2496
	 Train time/token: 133509283
	 Train time/token_in_epoch: 2547840
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0355
	 Train memory/reserved_mem: 33.3280
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.5714
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 18.2916
	 Train throughput/batches_per_sec: 0.0328
	 Train throughput/samples_per_sec: 2.0997
	 Train throughput/device/batches_per_sec: 0.0328
	 Train throughput/device/samples_per_sec: 2.0997
	 Train time/train: 16.8347
	 Train time/val: 2.2693
	 Train time/total: 19.1040
[2025-04-12 05:58:25,936] [INFO] [logging.py:96:log_dist] [Rank 0] step=2050, skipped=0, lr=[4.714427860696518e-05], mom=[[0.9, 0.98]]
[2025-04-12 05:58:25,937] [INFO] [timer.py:260:stop] epoch=0/micro_step=65600/global_step=2050, RunningAvgSamplesPerSec=2.2697880428380843, CurrSamplesPerSec=2.4010071878663757, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:03:26,017] [INFO] [logging.py:96:log_dist] [Rank 0] step=2060, skipped=0, lr=[4.69452736318408e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:03:26,018] [INFO] [timer.py:260:stop] epoch=0/micro_step=65920/global_step=2060, RunningAvgSamplesPerSec=2.2696488779834634, CurrSamplesPerSec=2.250550016604417, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:08:24,400] [INFO] [logging.py:96:log_dist] [Rank 0] step=2070, skipped=0, lr=[4.6746268656716424e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:08:24,401] [INFO] [timer.py:260:stop] epoch=0/micro_step=66240/global_step=2070, RunningAvgSamplesPerSec=2.269549710948228, CurrSamplesPerSec=2.173882459204778, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:13:24,359] [INFO] [logging.py:96:log_dist] [Rank 0] step=2080, skipped=0, lr=[4.654726368159205e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:13:24,360] [INFO] [timer.py:260:stop] epoch=0/micro_step=66560/global_step=2080, RunningAvgSamplesPerSec=2.2693927678478296, CurrSamplesPerSec=2.272922571688619, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:18:26,086] [INFO] [logging.py:96:log_dist] [Rank 0] step=2090, skipped=0, lr=[4.634825870646767e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:18:26,087] [INFO] [timer.py:260:stop] epoch=0/micro_step=66880/global_step=2090, RunningAvgSamplesPerSec=2.2692107475765972, CurrSamplesPerSec=2.121185076633533, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=6][batch=90/402]:
	 Train time/batch: 2099
	 Train time/sample: 134041
	 Train time/batch_in_epoch: 89
	 Train time/sample_in_epoch: 5696
	 Train time/token: 136774435
	 Train time/token_in_epoch: 5812992
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0376
	 Train memory/reserved_mem: 33.3280
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.5935
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 17.8862
	 Train throughput/batches_per_sec: 0.0329
	 Train throughput/samples_per_sec: 2.1072
	 Train throughput/device/batches_per_sec: 0.0329
	 Train throughput/device/samples_per_sec: 2.1072
	 Train time/train: 17.2510
	 Train time/val: 2.2693
	 Train time/total: 19.5203
[2025-04-12 06:23:29,669] [INFO] [logging.py:96:log_dist] [Rank 0] step=2100, skipped=0, lr=[4.6149253731343283e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:23:29,670] [INFO] [timer.py:260:stop] epoch=0/micro_step=67200/global_step=2100, RunningAvgSamplesPerSec=2.2689683597518515, CurrSamplesPerSec=2.1683948324476683, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:28:24,911] [INFO] [logging.py:96:log_dist] [Rank 0] step=2110, skipped=0, lr=[4.59502487562189e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:28:24,912] [INFO] [timer.py:260:stop] epoch=0/micro_step=67520/global_step=2110, RunningAvgSamplesPerSec=2.269031094583523, CurrSamplesPerSec=2.268277883278295, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:33:27,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=2120, skipped=0, lr=[4.575124378109453e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:33:27,405] [INFO] [timer.py:260:stop] epoch=0/micro_step=67840/global_step=2120, RunningAvgSamplesPerSec=2.2687919597454447, CurrSamplesPerSec=2.287296572311672, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:38:25,388] [INFO] [logging.py:96:log_dist] [Rank 0] step=2130, skipped=0, lr=[4.555223880597016e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:38:25,389] [INFO] [timer.py:260:stop] epoch=0/micro_step=68160/global_step=2130, RunningAvgSamplesPerSec=2.268725393288224, CurrSamplesPerSec=2.278515515731882, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:43:26,102] [INFO] [logging.py:96:log_dist] [Rank 0] step=2140, skipped=0, lr=[4.535323383084578e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:43:26,103] [INFO] [timer.py:260:stop] epoch=0/micro_step=68480/global_step=2140, RunningAvgSamplesPerSec=2.2685674868943377, CurrSamplesPerSec=2.288573313995681, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=6][batch=140/402]:
	 Train time/batch: 2149
	 Train time/sample: 137241
	 Train time/batch_in_epoch: 139
	 Train time/sample_in_epoch: 8896
	 Train time/token: 140040419
	 Train time/token_in_epoch: 9078976
	 Train memory/allocated_mem: 3.3489
	 Train memory/active_mem: 3.3489
	 Train memory/inactive_mem: 0.0380
	 Train memory/reserved_mem: 33.2820
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.5547
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 17.4795
	 Train throughput/batches_per_sec: 0.0337
	 Train throughput/samples_per_sec: 2.1569
	 Train throughput/device/batches_per_sec: 0.0337
	 Train throughput/device/samples_per_sec: 2.1569
	 Train time/train: 17.6663
	 Train time/val: 2.2693
	 Train time/total: 19.9356
[2025-04-12 06:48:24,757] [INFO] [logging.py:96:log_dist] [Rank 0] step=2150, skipped=0, lr=[4.5154228855721397e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:48:24,758] [INFO] [timer.py:260:stop] epoch=0/micro_step=68800/global_step=2150, RunningAvgSamplesPerSec=2.2684672225203957, CurrSamplesPerSec=2.3039428197784977, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:53:25,881] [INFO] [logging.py:96:log_dist] [Rank 0] step=2160, skipped=0, lr=[4.4955223880597016e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:53:25,882] [INFO] [timer.py:260:stop] epoch=0/micro_step=69120/global_step=2160, RunningAvgSamplesPerSec=2.2682915949928892, CurrSamplesPerSec=2.187835526362332, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 06:58:22,630] [INFO] [logging.py:96:log_dist] [Rank 0] step=2170, skipped=0, lr=[4.475621890547264e-05], mom=[[0.9, 0.98]]
[2025-04-12 06:58:22,631] [INFO] [timer.py:260:stop] epoch=0/micro_step=69440/global_step=2170, RunningAvgSamplesPerSec=2.2683309773956344, CurrSamplesPerSec=2.242526158423588, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:03:25,745] [INFO] [logging.py:96:log_dist] [Rank 0] step=2180, skipped=0, lr=[4.455721393034827e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:03:25,746] [INFO] [timer.py:260:stop] epoch=0/micro_step=69760/global_step=2180, RunningAvgSamplesPerSec=2.268096475509981, CurrSamplesPerSec=2.221450503463238, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:08:25,462] [INFO] [logging.py:96:log_dist] [Rank 0] step=2190, skipped=0, lr=[4.435820895522389e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:08:25,462] [INFO] [timer.py:260:stop] epoch=0/micro_step=70080/global_step=2190, RunningAvgSamplesPerSec=2.2679891265192347, CurrSamplesPerSec=2.2904296950926057, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=6][batch=190/402]:
	 Train time/batch: 2199
	 Train time/sample: 140441
	 Train time/batch_in_epoch: 189
	 Train time/sample_in_epoch: 12096
	 Train time/token: 143308067
	 Train time/token_in_epoch: 12346624
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0375
	 Train memory/reserved_mem: 33.3280
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.5414
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 17.0740
	 Train throughput/batches_per_sec: 0.0338
	 Train throughput/samples_per_sec: 2.1628
	 Train throughput/device/batches_per_sec: 0.0338
	 Train throughput/device/samples_per_sec: 2.1628
	 Train time/train: 18.0836
	 Train time/val: 2.2693
	 Train time/total: 20.3529
[2025-04-12 07:13:23,435] [INFO] [logging.py:96:log_dist] [Rank 0] step=2200, skipped=0, lr=[4.41592039800995e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:13:23,436] [INFO] [timer.py:260:stop] epoch=0/micro_step=70400/global_step=2200, RunningAvgSamplesPerSec=2.2679241217665274, CurrSamplesPerSec=2.3070909301429507, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:18:24,001] [INFO] [logging.py:96:log_dist] [Rank 0] step=2210, skipped=0, lr=[4.396019900497512e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:18:24,002] [INFO] [timer.py:260:stop] epoch=0/micro_step=70720/global_step=2210, RunningAvgSamplesPerSec=2.2677666861569317, CurrSamplesPerSec=2.300144949115715, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:23:25,829] [INFO] [logging.py:96:log_dist] [Rank 0] step=2220, skipped=0, lr=[4.376119402985075e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:23:25,831] [INFO] [timer.py:260:stop] epoch=0/micro_step=71040/global_step=2220, RunningAvgSamplesPerSec=2.267584878413173, CurrSamplesPerSec=2.184130865273581, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:28:28,030] [INFO] [logging.py:96:log_dist] [Rank 0] step=2230, skipped=0, lr=[4.3562189054726376e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:28:28,031] [INFO] [timer.py:260:stop] epoch=0/micro_step=71360/global_step=2230, RunningAvgSamplesPerSec=2.267405989747182, CurrSamplesPerSec=2.2949458723784164, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:33:28,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=2240, skipped=0, lr=[4.3363184079601996e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:33:28,185] [INFO] [timer.py:260:stop] epoch=0/micro_step=71680/global_step=2240, RunningAvgSamplesPerSec=2.2672661474193174, CurrSamplesPerSec=2.1975681062599635, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=6][batch=240/402]:
	 Train time/batch: 2249
	 Train time/sample: 143641
	 Train time/batch_in_epoch: 239
	 Train time/sample_in_epoch: 15296
	 Train time/token: 146573091
	 Train time/token_in_epoch: 15611648
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0438
	 Train memory/reserved_mem: 33.3280
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.6405
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 16.6680
	 Train throughput/batches_per_sec: 0.0330
	 Train throughput/samples_per_sec: 2.1116
	 Train throughput/device/batches_per_sec: 0.0330
	 Train throughput/device/samples_per_sec: 2.1116
	 Train time/train: 18.5010
	 Train time/val: 2.2693
	 Train time/total: 20.7703
[2025-04-12 07:38:27,493] [INFO] [logging.py:96:log_dist] [Rank 0] step=2250, skipped=0, lr=[4.3164179104477616e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:38:27,494] [INFO] [timer.py:260:stop] epoch=0/micro_step=72000/global_step=2250, RunningAvgSamplesPerSec=2.267186349308094, CurrSamplesPerSec=2.189353670797308, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:43:30,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=2260, skipped=0, lr=[4.2965174129353236e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:43:30,323] [INFO] [timer.py:260:stop] epoch=0/micro_step=72320/global_step=2260, RunningAvgSamplesPerSec=2.2669745025266788, CurrSamplesPerSec=2.1993954870154364, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:48:33,313] [INFO] [logging.py:96:log_dist] [Rank 0] step=2270, skipped=0, lr=[4.276616915422885e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:48:33,314] [INFO] [timer.py:260:stop] epoch=0/micro_step=72640/global_step=2270, RunningAvgSamplesPerSec=2.266743771460768, CurrSamplesPerSec=2.3309879114382923, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:53:43,891] [INFO] [logging.py:96:log_dist] [Rank 0] step=2280, skipped=0, lr=[4.2567164179104476e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:53:43,892] [INFO] [timer.py:260:stop] epoch=0/micro_step=72960/global_step=2280, RunningAvgSamplesPerSec=2.2662845932110964, CurrSamplesPerSec=2.2376740866385654, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 07:58:42,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=2290, skipped=0, lr=[4.236815920398011e-05], mom=[[0.9, 0.98]]
[2025-04-12 07:58:42,547] [INFO] [timer.py:260:stop] epoch=0/micro_step=73280/global_step=2290, RunningAvgSamplesPerSec=2.266254519665232, CurrSamplesPerSec=2.2697497657452437, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=6][batch=290/402]:
	 Train time/batch: 2299
	 Train time/sample: 146841
	 Train time/batch_in_epoch: 289
	 Train time/sample_in_epoch: 18496
	 Train time/token: 149838307
	 Train time/token_in_epoch: 18876864
	 Train memory/allocated_mem: 3.3470
	 Train memory/active_mem: 3.3470
	 Train memory/inactive_mem: 0.0357
	 Train memory/reserved_mem: 33.3280
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.6065
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 16.2641
	 Train throughput/batches_per_sec: 0.0329
	 Train throughput/samples_per_sec: 2.1043
	 Train throughput/device/batches_per_sec: 0.0329
	 Train throughput/device/samples_per_sec: 2.1043
	 Train time/train: 18.9218
	 Train time/val: 2.2693
	 Train time/total: 21.1911
[2025-04-12 08:03:46,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=2300, skipped=0, lr=[4.216915422885572e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:03:46,994] [INFO] [timer.py:260:stop] epoch=0/micro_step=73600/global_step=2300, RunningAvgSamplesPerSec=2.2660124676328874, CurrSamplesPerSec=2.174770687192019, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 08:08:48,394] [INFO] [logging.py:96:log_dist] [Rank 0] step=2310, skipped=0, lr=[4.197014925373134e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:08:48,395] [INFO] [timer.py:260:stop] epoch=0/micro_step=73920/global_step=2310, RunningAvgSamplesPerSec=2.265851178609788, CurrSamplesPerSec=2.2714499747321875, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 08:13:52,757] [INFO] [logging.py:96:log_dist] [Rank 0] step=2320, skipped=0, lr=[4.177114427860697e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:13:52,758] [INFO] [timer.py:260:stop] epoch=0/micro_step=74240/global_step=2320, RunningAvgSamplesPerSec=2.2656242115971374, CurrSamplesPerSec=2.17526129974549, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 08:18:53,416] [INFO] [logging.py:96:log_dist] [Rank 0] step=2330, skipped=0, lr=[4.1572139303482596e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:18:53,417] [INFO] [timer.py:260:stop] epoch=0/micro_step=74560/global_step=2330, RunningAvgSamplesPerSec=2.265479813806053, CurrSamplesPerSec=2.1907382678711884, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 08:23:52,833] [INFO] [logging.py:96:log_dist] [Rank 0] step=2340, skipped=0, lr=[4.1373134328358216e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:23:52,834] [INFO] [timer.py:260:stop] epoch=0/micro_step=74880/global_step=2340, RunningAvgSamplesPerSec=2.265378528419706, CurrSamplesPerSec=2.3212694802201908, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=6][batch=340/402]:
	 Train time/batch: 2349
	 Train time/sample: 150041
	 Train time/batch_in_epoch: 339
	 Train time/sample_in_epoch: 21696
	 Train time/token: 153105251
	 Train time/token_in_epoch: 22143808
	 Train memory/allocated_mem: 3.3474
	 Train memory/active_mem: 3.3474
	 Train memory/inactive_mem: 0.0437
	 Train memory/reserved_mem: 33.3280
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.5996
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 15.8585
	 Train throughput/batches_per_sec: 0.0332
	 Train throughput/samples_per_sec: 2.1266
	 Train throughput/device/batches_per_sec: 0.0332
	 Train throughput/device/samples_per_sec: 2.1266
	 Train time/train: 19.3412
	 Train time/val: 2.2693
	 Train time/total: 21.6105
[2025-04-12 08:28:51,093] [INFO] [logging.py:96:log_dist] [Rank 0] step=2350, skipped=0, lr=[4.1174129353233836e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:28:51,094] [INFO] [timer.py:260:stop] epoch=0/micro_step=75200/global_step=2350, RunningAvgSamplesPerSec=2.265345513320579, CurrSamplesPerSec=2.24584057745752, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 08:33:52,679] [INFO] [logging.py:96:log_dist] [Rank 0] step=2360, skipped=0, lr=[4.097512437810945e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:33:52,680] [INFO] [timer.py:260:stop] epoch=0/micro_step=75520/global_step=2360, RunningAvgSamplesPerSec=2.2651917608440795, CurrSamplesPerSec=2.189583291444595, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 08:38:50,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=2370, skipped=0, lr=[4.077611940298507e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:38:50,405] [INFO] [timer.py:260:stop] epoch=0/micro_step=75840/global_step=2370, RunningAvgSamplesPerSec=2.2651819496359185, CurrSamplesPerSec=2.1824689393736874, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 08:43:50,380] [INFO] [logging.py:96:log_dist] [Rank 0] step=2380, skipped=0, lr=[4.0577114427860695e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:43:50,380] [INFO] [timer.py:260:stop] epoch=0/micro_step=76160/global_step=2380, RunningAvgSamplesPerSec=2.265064005424364, CurrSamplesPerSec=2.1698685676300244, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 08:48:53,708] [INFO] [logging.py:96:log_dist] [Rank 0] step=2390, skipped=0, lr=[4.037810945273632e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:48:53,709] [INFO] [timer.py:260:stop] epoch=0/micro_step=76480/global_step=2390, RunningAvgSamplesPerSec=2.2648680965139505, CurrSamplesPerSec=2.2229350427245675, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=6][batch=390/402]:
	 Train time/batch: 2399
	 Train time/sample: 153241
	 Train time/batch_in_epoch: 389
	 Train time/sample_in_epoch: 24896
	 Train time/token: 156368739
	 Train time/token_in_epoch: 25407296
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0438
	 Train memory/reserved_mem: 33.2610
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.5604
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 15.4519
	 Train throughput/batches_per_sec: 0.0325
	 Train throughput/samples_per_sec: 2.0828
	 Train throughput/device/batches_per_sec: 0.0325
	 Train throughput/device/samples_per_sec: 2.0828
	 Train time/train: 19.7600
	 Train time/val: 2.2693
	 Train time/total: 22.0293
[2025-04-12 08:53:54,950] [INFO] [logging.py:96:log_dist] [Rank 0] step=2400, skipped=0, lr=[4.017910447761194e-05], mom=[[0.9, 0.98]]
[2025-04-12 08:53:54,951] [INFO] [timer.py:260:stop] epoch=0/micro_step=76800/global_step=2400, RunningAvgSamplesPerSec=2.2647518919170953, CurrSamplesPerSec=2.5044043659362436, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[Eval batch=1/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on in-domain-standard-q-answer-eval data:
	 Eval metrics/in-domain-standard-q-answer-eval/QA-EM: 0.0448
	 Eval metrics/in-domain-standard-q-answer-eval/QA-F1: 0.1767
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@1-att: 0.5000
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@10-att: 0.6250
[Eval batch=1/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on out-of-domain-standard-q-answer-eval data:
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-EM: 0.0506
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-F1: 0.1784
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@1-att: 0.0040
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@10-att: 0.0198
[2025-04-12 09:24:21,539] [INFO] [logging.py:96:log_dist] [Rank 0] step=2410, skipped=0, lr=[3.996019900497513e-05], mom=[[0.9, 0.98]]
[2025-04-12 09:24:21,541] [INFO] [timer.py:260:stop] epoch=0/micro_step=77120/global_step=2410, RunningAvgSamplesPerSec=2.264433784093701, CurrSamplesPerSec=2.3104211656476936, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 09:29:29,377] [INFO] [logging.py:96:log_dist] [Rank 0] step=2420, skipped=0, lr=[3.976119402985075e-05], mom=[[0.9, 0.98]]
[2025-04-12 09:29:29,379] [INFO] [timer.py:260:stop] epoch=0/micro_step=77440/global_step=2420, RunningAvgSamplesPerSec=2.2640790713872696, CurrSamplesPerSec=2.1807951721297525, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 09:34:27,765] [INFO] [logging.py:96:log_dist] [Rank 0] step=2430, skipped=0, lr=[3.9562189054726374e-05], mom=[[0.9, 0.98]]
[2025-04-12 09:34:27,766] [INFO] [timer.py:260:stop] epoch=0/micro_step=77760/global_step=2430, RunningAvgSamplesPerSec=2.2640368828846213, CurrSamplesPerSec=2.1733281535503868, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 09:39:24,710] [INFO] [logging.py:96:log_dist] [Rank 0] step=2440, skipped=0, lr=[3.9363184079601994e-05], mom=[[0.9, 0.98]]
[2025-04-12 09:39:24,711] [INFO] [timer.py:260:stop] epoch=0/micro_step=78080/global_step=2440, RunningAvgSamplesPerSec=2.2640513337210395, CurrSamplesPerSec=2.3613146288433327, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=7][batch=38/402]:
	 Train time/epoch: 6
	 Train time/batch: 2449
	 Train time/sample: 156382
	 Train time/batch_in_epoch: 37
	 Train time/sample_in_epoch: 2368
	 Train time/token: 159568926
	 Train time/token_in_epoch: 2412288
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0417
	 Train memory/reserved_mem: 33.2630
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.4110
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 14.6166
	 Train throughput/batches_per_sec: 0.0331
	 Train throughput/samples_per_sec: 2.1166
	 Train throughput/device/batches_per_sec: 0.0331
	 Train throughput/device/samples_per_sec: 2.1166
	 Train time/train: 20.1714
	 Train time/val: 2.6911
	 Train time/total: 22.8626
[2025-04-12 09:44:36,580] [INFO] [logging.py:96:log_dist] [Rank 0] step=2450, skipped=0, lr=[3.916417910447762e-05], mom=[[0.9, 0.98]]
[2025-04-12 09:44:36,581] [INFO] [timer.py:260:stop] epoch=0/micro_step=78400/global_step=2450, RunningAvgSamplesPerSec=2.263596516658366, CurrSamplesPerSec=2.174652186670689, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 09:49:41,645] [INFO] [logging.py:96:log_dist] [Rank 0] step=2460, skipped=0, lr=[3.896517412935324e-05], mom=[[0.9, 0.98]]
[2025-04-12 09:49:41,646] [INFO] [timer.py:260:stop] epoch=0/micro_step=78720/global_step=2460, RunningAvgSamplesPerSec=2.263335331364467, CurrSamplesPerSec=2.1348363480348276, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 09:54:43,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=2470, skipped=0, lr=[3.876616915422887e-05], mom=[[0.9, 0.98]]
[2025-04-12 09:54:43,405] [INFO] [timer.py:260:stop] epoch=0/micro_step=79040/global_step=2470, RunningAvgSamplesPerSec=2.263196924699756, CurrSamplesPerSec=2.3199639073741753, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 09:59:48,591] [INFO] [logging.py:96:log_dist] [Rank 0] step=2480, skipped=0, lr=[3.8567164179104473e-05], mom=[[0.9, 0.98]]
[2025-04-12 09:59:48,592] [INFO] [timer.py:260:stop] epoch=0/micro_step=79360/global_step=2480, RunningAvgSamplesPerSec=2.2629386169892824, CurrSamplesPerSec=2.138548910411042, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 10:04:56,447] [INFO] [logging.py:96:log_dist] [Rank 0] step=2490, skipped=0, lr=[3.83681592039801e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:04:56,448] [INFO] [timer.py:260:stop] epoch=0/micro_step=79680/global_step=2490, RunningAvgSamplesPerSec=2.2626283581881528, CurrSamplesPerSec=2.1375930732530364, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=7][batch=88/402]:
	 Train time/batch: 2499
	 Train time/sample: 159582
	 Train time/batch_in_epoch: 87
	 Train time/sample_in_epoch: 5568
	 Train time/token: 162832606
	 Train time/token_in_epoch: 5675968
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0375
	 Train memory/reserved_mem: 33.2630
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.4587
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 14.2136
	 Train throughput/batches_per_sec: 0.0328
	 Train throughput/samples_per_sec: 2.1008
	 Train throughput/device/batches_per_sec: 0.0328
	 Train throughput/device/samples_per_sec: 2.1008
	 Train time/train: 20.5974
	 Train time/val: 2.6911
	 Train time/total: 23.2885
[2025-04-12 10:10:02,962] [INFO] [logging.py:96:log_dist] [Rank 0] step=2500, skipped=0, lr=[3.816915422885572e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:10:02,963] [INFO] [timer.py:260:stop] epoch=0/micro_step=80000/global_step=2500, RunningAvgSamplesPerSec=2.2623354924524604, CurrSamplesPerSec=2.291498303482315, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 10:15:13,803] [INFO] [logging.py:96:log_dist] [Rank 0] step=2510, skipped=0, lr=[3.797014925373135e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:15:13,804] [INFO] [timer.py:260:stop] epoch=0/micro_step=80320/global_step=2510, RunningAvgSamplesPerSec=2.2619401730287314, CurrSamplesPerSec=2.177129233599175, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 10:20:19,735] [INFO] [logging.py:96:log_dist] [Rank 0] step=2520, skipped=0, lr=[3.777114427860697e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:20:19,737] [INFO] [timer.py:260:stop] epoch=0/micro_step=80640/global_step=2520, RunningAvgSamplesPerSec=2.261676291707119, CurrSamplesPerSec=2.217224694730799, MemAllocated=3.58GB, MaxMemAllocated=17.36GB
[2025-04-12 10:25:29,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=2530, skipped=0, lr=[3.757213930348259e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:25:29,399] [INFO] [timer.py:260:stop] epoch=0/micro_step=80960/global_step=2530, RunningAvgSamplesPerSec=2.2613105065394516, CurrSamplesPerSec=2.1868515419002237, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 10:30:34,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=2540, skipped=0, lr=[3.737313432835821e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:30:34,191] [INFO] [timer.py:260:stop] epoch=0/micro_step=81280/global_step=2540, RunningAvgSamplesPerSec=2.261068391499924, CurrSamplesPerSec=2.150634602974587, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=7][batch=138/402]:
	 Train time/batch: 2549
	 Train time/sample: 162782
	 Train time/batch_in_epoch: 137
	 Train time/sample_in_epoch: 8768
	 Train time/token: 166097182
	 Train time/token_in_epoch: 8940544
	 Train memory/allocated_mem: 3.3471
	 Train memory/active_mem: 3.3471
	 Train memory/inactive_mem: 0.0377
	 Train memory/reserved_mem: 33.2630
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.5230
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 13.8107
	 Train throughput/batches_per_sec: 0.0322
	 Train throughput/samples_per_sec: 2.0612
	 Train throughput/device/batches_per_sec: 0.0322
	 Train throughput/device/samples_per_sec: 2.0612
	 Train time/train: 21.0250
	 Train time/val: 2.6911
	 Train time/total: 23.7161
[2025-04-12 10:35:46,836] [INFO] [logging.py:96:log_dist] [Rank 0] step=2550, skipped=0, lr=[3.717412935323384e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:35:46,837] [INFO] [timer.py:260:stop] epoch=0/micro_step=81600/global_step=2550, RunningAvgSamplesPerSec=2.260660385265795, CurrSamplesPerSec=2.1265891103928842, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 10:40:51,357] [INFO] [logging.py:96:log_dist] [Rank 0] step=2560, skipped=0, lr=[3.6975124378109446e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:40:51,359] [INFO] [timer.py:260:stop] epoch=0/micro_step=81920/global_step=2560, RunningAvgSamplesPerSec=2.2604493447466085, CurrSamplesPerSec=2.3065669624677207, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 10:45:51,107] [INFO] [logging.py:96:log_dist] [Rank 0] step=2570, skipped=0, lr=[3.677611940298507e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:45:51,108] [INFO] [timer.py:260:stop] epoch=0/micro_step=82240/global_step=2570, RunningAvgSamplesPerSec=2.2603679186282735, CurrSamplesPerSec=2.0816852897185534, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 10:51:00,434] [INFO] [logging.py:96:log_dist] [Rank 0] step=2580, skipped=0, lr=[3.657711442786069e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:51:00,434] [INFO] [timer.py:260:stop] epoch=0/micro_step=82560/global_step=2580, RunningAvgSamplesPerSec=2.2600020857541803, CurrSamplesPerSec=2.14019820784148, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 10:56:10,026] [INFO] [logging.py:96:log_dist] [Rank 0] step=2590, skipped=0, lr=[3.637810945273632e-05], mom=[[0.9, 0.98]]
[2025-04-12 10:56:10,027] [INFO] [timer.py:260:stop] epoch=0/micro_step=82880/global_step=2590, RunningAvgSamplesPerSec=2.2596808992084436, CurrSamplesPerSec=2.140355288885998, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=7][batch=188/402]:
	 Train time/batch: 2599
	 Train time/sample: 165982
	 Train time/batch_in_epoch: 187
	 Train time/sample_in_epoch: 11968
	 Train time/token: 169362590
	 Train time/token_in_epoch: 12205952
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0418
	 Train memory/reserved_mem: 33.2630
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.4717
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 13.4059
	 Train throughput/batches_per_sec: 0.0322
	 Train throughput/samples_per_sec: 2.0593
	 Train throughput/device/batches_per_sec: 0.0322
	 Train throughput/device/samples_per_sec: 2.0593
	 Train time/train: 21.4509
	 Train time/val: 2.6911
	 Train time/total: 24.1421
[2025-04-12 11:01:17,358] [INFO] [logging.py:96:log_dist] [Rank 0] step=2600, skipped=0, lr=[3.617910447761194e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:01:17,359] [INFO] [timer.py:260:stop] epoch=0/micro_step=83200/global_step=2600, RunningAvgSamplesPerSec=2.2593908929420548, CurrSamplesPerSec=2.303226358738863, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 11:06:25,276] [INFO] [logging.py:96:log_dist] [Rank 0] step=2610, skipped=0, lr=[3.5980099502487566e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:06:25,277] [INFO] [timer.py:260:stop] epoch=0/micro_step=83520/global_step=2610, RunningAvgSamplesPerSec=2.259068826416525, CurrSamplesPerSec=2.162599369856343, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 11:11:34,350] [INFO] [logging.py:96:log_dist] [Rank 0] step=2620, skipped=0, lr=[3.5781094527363186e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:11:34,351] [INFO] [timer.py:260:stop] epoch=0/micro_step=83840/global_step=2620, RunningAvgSamplesPerSec=2.2587062074267803, CurrSamplesPerSec=2.37103103606209, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 11:16:43,821] [INFO] [logging.py:96:log_dist] [Rank 0] step=2630, skipped=0, lr=[3.558208955223881e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:16:43,822] [INFO] [timer.py:260:stop] epoch=0/micro_step=84160/global_step=2630, RunningAvgSamplesPerSec=2.2583382476549096, CurrSamplesPerSec=2.127734088280075, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 11:21:47,692] [INFO] [logging.py:96:log_dist] [Rank 0] step=2640, skipped=0, lr=[3.538308457711443e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:21:47,693] [INFO] [timer.py:260:stop] epoch=0/micro_step=84480/global_step=2640, RunningAvgSamplesPerSec=2.2581444898792196, CurrSamplesPerSec=2.1161772602009488, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=7][batch=238/402]:
	 Train time/batch: 2649
	 Train time/sample: 169182
	 Train time/batch_in_epoch: 237
	 Train time/sample_in_epoch: 15168
	 Train time/token: 172628766
	 Train time/token_in_epoch: 15472128
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0396
	 Train memory/reserved_mem: 33.2630
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.4596
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 13.0011
	 Train throughput/batches_per_sec: 0.0323
	 Train throughput/samples_per_sec: 2.0704
	 Train throughput/device/batches_per_sec: 0.0323
	 Train throughput/device/samples_per_sec: 2.0704
	 Train time/train: 21.8784
	 Train time/val: 2.6911
	 Train time/total: 24.5695
[2025-04-12 11:26:54,077] [INFO] [logging.py:96:log_dist] [Rank 0] step=2650, skipped=0, lr=[3.5184079601990046e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:26:54,079] [INFO] [timer.py:260:stop] epoch=0/micro_step=84800/global_step=2650, RunningAvgSamplesPerSec=2.257867898504492, CurrSamplesPerSec=2.1558394055886176, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 11:31:55,769] [INFO] [logging.py:96:log_dist] [Rank 0] step=2660, skipped=0, lr=[3.4985074626865666e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:31:55,770] [INFO] [timer.py:260:stop] epoch=0/micro_step=85120/global_step=2660, RunningAvgSamplesPerSec=2.2577346753863368, CurrSamplesPerSec=2.1938627310262824, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 11:37:05,744] [INFO] [logging.py:96:log_dist] [Rank 0] step=2670, skipped=0, lr=[3.478606965174129e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:37:05,745] [INFO] [timer.py:260:stop] epoch=0/micro_step=85440/global_step=2670, RunningAvgSamplesPerSec=2.257393674471946, CurrSamplesPerSec=2.108322088077832, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 11:42:14,147] [INFO] [logging.py:96:log_dist] [Rank 0] step=2680, skipped=0, lr=[3.458706467661691e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:42:14,148] [INFO] [timer.py:260:stop] epoch=0/micro_step=85760/global_step=2680, RunningAvgSamplesPerSec=2.257064868932733, CurrSamplesPerSec=2.2407783843265268, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 11:47:20,452] [INFO] [logging.py:96:log_dist] [Rank 0] step=2690, skipped=0, lr=[3.438805970149254e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:47:20,453] [INFO] [timer.py:260:stop] epoch=0/micro_step=86080/global_step=2690, RunningAvgSamplesPerSec=2.2568199492004997, CurrSamplesPerSec=2.271574088794511, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=7][batch=288/402]:
	 Train time/batch: 2699
	 Train time/sample: 172382
	 Train time/batch_in_epoch: 287
	 Train time/sample_in_epoch: 18368
	 Train time/token: 175896926
	 Train time/token_in_epoch: 18740288
	 Train memory/allocated_mem: 3.3474
	 Train memory/active_mem: 3.3474
	 Train memory/inactive_mem: 0.0521
	 Train memory/reserved_mem: 33.2630
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.4622
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 12.5945
	 Train throughput/batches_per_sec: 0.0324
	 Train throughput/samples_per_sec: 2.0757
	 Train throughput/device/batches_per_sec: 0.0324
	 Train throughput/device/samples_per_sec: 2.0757
	 Train time/train: 22.3039
	 Train time/val: 2.6911
	 Train time/total: 24.9950
[2025-04-12 11:52:28,095] [INFO] [logging.py:96:log_dist] [Rank 0] step=2700, skipped=0, lr=[3.418905472636816e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:52:28,096] [INFO] [timer.py:260:stop] epoch=0/micro_step=86400/global_step=2700, RunningAvgSamplesPerSec=2.2565296291904264, CurrSamplesPerSec=2.0902508083350995, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 11:57:40,226] [INFO] [logging.py:96:log_dist] [Rank 0] step=2710, skipped=0, lr=[3.3990049751243786e-05], mom=[[0.9, 0.98]]
[2025-04-12 11:57:40,227] [INFO] [timer.py:260:stop] epoch=0/micro_step=86720/global_step=2710, RunningAvgSamplesPerSec=2.2561177443156386, CurrSamplesPerSec=2.2487308851602434, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 12:02:59,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=2720, skipped=0, lr=[3.3791044776119406e-05], mom=[[0.9, 0.98]]
[2025-04-12 12:02:59,399] [INFO] [timer.py:260:stop] epoch=0/micro_step=87040/global_step=2720, RunningAvgSamplesPerSec=2.2554891187635, CurrSamplesPerSec=2.0955865968121814, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 12:08:13,013] [INFO] [logging.py:96:log_dist] [Rank 0] step=2730, skipped=0, lr=[3.359203980099503e-05], mom=[[0.9, 0.98]]
[2025-04-12 12:08:13,014] [INFO] [timer.py:260:stop] epoch=0/micro_step=87360/global_step=2730, RunningAvgSamplesPerSec=2.2550386422964936, CurrSamplesPerSec=2.1004703657496155, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 12:13:21,811] [INFO] [logging.py:96:log_dist] [Rank 0] step=2740, skipped=0, lr=[3.339303482587064e-05], mom=[[0.9, 0.98]]
[2025-04-12 12:13:21,812] [INFO] [timer.py:260:stop] epoch=0/micro_step=87680/global_step=2740, RunningAvgSamplesPerSec=2.2546879141914804, CurrSamplesPerSec=2.3011459847841818, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=7][batch=338/402]:
	 Train time/batch: 2749
	 Train time/sample: 175582
	 Train time/batch_in_epoch: 337
	 Train time/sample_in_epoch: 21568
	 Train time/token: 179165086
	 Train time/token_in_epoch: 22008448
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0438
	 Train memory/reserved_mem: 33.2630
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.3581
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 12.1908
	 Train throughput/batches_per_sec: 0.0326
	 Train throughput/samples_per_sec: 2.0863
	 Train throughput/device/batches_per_sec: 0.0326
	 Train throughput/device/samples_per_sec: 2.0863
	 Train time/train: 22.7371
	 Train time/val: 2.6911
	 Train time/total: 25.4282
[2025-04-12 12:18:27,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=2750, skipped=0, lr=[3.3194029850746265e-05], mom=[[0.9, 0.98]]
[2025-04-12 12:18:27,399] [INFO] [timer.py:260:stop] epoch=0/micro_step=88000/global_step=2750, RunningAvgSamplesPerSec=2.2544117552797833, CurrSamplesPerSec=2.262937468501462, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 12:23:34,490] [INFO] [logging.py:96:log_dist] [Rank 0] step=2760, skipped=0, lr=[3.2995024875621885e-05], mom=[[0.9, 0.98]]
[2025-04-12 12:23:34,491] [INFO] [timer.py:260:stop] epoch=0/micro_step=88320/global_step=2760, RunningAvgSamplesPerSec=2.2541200233334076, CurrSamplesPerSec=2.1676544355370333, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 12:28:33,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=2770, skipped=0, lr=[3.279601990049751e-05], mom=[[0.9, 0.98]]
[2025-04-12 12:28:33,600] [INFO] [timer.py:260:stop] epoch=0/micro_step=88640/global_step=2770, RunningAvgSamplesPerSec=2.2540358568996735, CurrSamplesPerSec=2.342208532020297, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 12:33:45,436] [INFO] [logging.py:96:log_dist] [Rank 0] step=2780, skipped=0, lr=[3.259701492537313e-05], mom=[[0.9, 0.98]]
[2025-04-12 12:33:45,437] [INFO] [timer.py:260:stop] epoch=0/micro_step=88960/global_step=2780, RunningAvgSamplesPerSec=2.253604112533683, CurrSamplesPerSec=2.0987332807525707, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 12:38:54,668] [INFO] [logging.py:96:log_dist] [Rank 0] step=2790, skipped=0, lr=[3.239800995024876e-05], mom=[[0.9, 0.98]]
[2025-04-12 12:38:54,670] [INFO] [timer.py:260:stop] epoch=0/micro_step=89280/global_step=2790, RunningAvgSamplesPerSec=2.2532524860050103, CurrSamplesPerSec=2.2882132671323494, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=7][batch=388/402]:
	 Train time/batch: 2799
	 Train time/sample: 178782
	 Train time/batch_in_epoch: 387
	 Train time/sample_in_epoch: 24768
	 Train time/token: 182431518
	 Train time/token_in_epoch: 25274880
	 Train memory/allocated_mem: 3.3474
	 Train memory/active_mem: 3.3474
	 Train memory/inactive_mem: 0.0563
	 Train memory/reserved_mem: 33.2630
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.4877
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 11.7832
	 Train throughput/batches_per_sec: 0.0322
	 Train throughput/samples_per_sec: 2.0635
	 Train throughput/device/batches_per_sec: 0.0322
	 Train throughput/device/samples_per_sec: 2.0635
	 Train time/train: 23.1637
	 Train time/val: 2.6911
	 Train time/total: 25.8548
[2025-04-12 12:44:04,443] [INFO] [logging.py:96:log_dist] [Rank 0] step=2800, skipped=0, lr=[3.219900497512438e-05], mom=[[0.9, 0.98]]
[2025-04-12 12:44:04,444] [INFO] [timer.py:260:stop] epoch=0/micro_step=89600/global_step=2800, RunningAvgSamplesPerSec=2.2528949776018385, CurrSamplesPerSec=2.227891218539768, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[Eval batch=1/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on in-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on in-domain-standard-q-answer-eval data:
	 Eval metrics/in-domain-standard-q-answer-eval/QA-EM: 0.1250
	 Eval metrics/in-domain-standard-q-answer-eval/QA-F1: 0.2823
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@1-att: 0.5072
	 Eval metrics/in-domain-standard-q-answer-eval/Hits@10-att: 0.6448
[Eval batch=1/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=13/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=26/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=38/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=51/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=63/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=75/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=88/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=100/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=113/125] Eval on out-of-domain-standard-q-answer-eval data
[Eval batch=125/125] Eval on out-of-domain-standard-q-answer-eval data:
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-EM: 0.1146
	 Eval metrics/out-of-domain-standard-q-answer-eval/QA-F1: 0.2632
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@1-att: 0.0017
	 Eval metrics/out-of-domain-standard-q-answer-eval/Hits@10-att: 0.0209
[2025-04-12 13:14:56,027] [INFO] [logging.py:96:log_dist] [Rank 0] step=2810, skipped=0, lr=[3.1980099502487564e-05], mom=[[0.9, 0.98]]
[2025-04-12 13:14:56,028] [INFO] [timer.py:260:stop] epoch=0/micro_step=89920/global_step=2810, RunningAvgSamplesPerSec=2.2527154199588133, CurrSamplesPerSec=2.1224441723056606, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 13:20:05,229] [INFO] [logging.py:96:log_dist] [Rank 0] step=2820, skipped=0, lr=[3.1781094527363184e-05], mom=[[0.9, 0.98]]
[2025-04-12 13:20:05,230] [INFO] [timer.py:260:stop] epoch=0/micro_step=90240/global_step=2820, RunningAvgSamplesPerSec=2.25241295967768, CurrSamplesPerSec=2.0834474246562045, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 13:25:17,425] [INFO] [logging.py:96:log_dist] [Rank 0] step=2830, skipped=0, lr=[3.158208955223881e-05], mom=[[0.9, 0.98]]
[2025-04-12 13:25:17,426] [INFO] [timer.py:260:stop] epoch=0/micro_step=90560/global_step=2830, RunningAvgSamplesPerSec=2.25204336341715, CurrSamplesPerSec=2.3075562002258216, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 13:30:32,613] [INFO] [logging.py:96:log_dist] [Rank 0] step=2840, skipped=0, lr=[3.1383084577114424e-05], mom=[[0.9, 0.98]]
[2025-04-12 13:30:32,614] [INFO] [timer.py:260:stop] epoch=0/micro_step=90880/global_step=2840, RunningAvgSamplesPerSec=2.251589171225878, CurrSamplesPerSec=2.129958283088086, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=8][batch=36/402]:
	 Train time/epoch: 7
	 Train time/batch: 2849
	 Train time/sample: 181923
	 Train time/batch_in_epoch: 35
	 Train time/sample_in_epoch: 2240
	 Train time/token: 185634753
	 Train time/token_in_epoch: 2286720
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0459
	 Train memory/reserved_mem: 33.2630
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.2822
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 10.9545
	 Train throughput/batches_per_sec: 0.0319
	 Train throughput/samples_per_sec: 2.0414
	 Train throughput/device/batches_per_sec: 0.0319
	 Train throughput/device/samples_per_sec: 2.0414
	 Train time/train: 23.5865
	 Train time/val: 3.1211
	 Train time/total: 26.7077
[2025-04-12 13:35:45,158] [INFO] [logging.py:96:log_dist] [Rank 0] step=2850, skipped=0, lr=[3.118407960199006e-05], mom=[[0.9, 0.98]]
[2025-04-12 13:35:45,159] [INFO] [timer.py:260:stop] epoch=0/micro_step=91200/global_step=2850, RunningAvgSamplesPerSec=2.2511883635792747, CurrSamplesPerSec=2.1328597548112103, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 13:40:52,120] [INFO] [logging.py:96:log_dist] [Rank 0] step=2860, skipped=0, lr=[3.098507462686567e-05], mom=[[0.9, 0.98]]
[2025-04-12 13:40:52,121] [INFO] [timer.py:260:stop] epoch=0/micro_step=91520/global_step=2860, RunningAvgSamplesPerSec=2.2509529879232852, CurrSamplesPerSec=2.1750733396762434, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 13:46:00,584] [INFO] [logging.py:96:log_dist] [Rank 0] step=2870, skipped=0, lr=[3.078606965174129e-05], mom=[[0.9, 0.98]]
[2025-04-12 13:46:00,585] [INFO] [timer.py:260:stop] epoch=0/micro_step=91840/global_step=2870, RunningAvgSamplesPerSec=2.2506650357489537, CurrSamplesPerSec=2.139019377202858, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 13:51:08,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=2880, skipped=0, lr=[3.058706467661692e-05], mom=[[0.9, 0.98]]
[2025-04-12 13:51:08,814] [INFO] [timer.py:260:stop] epoch=0/micro_step=92160/global_step=2880, RunningAvgSamplesPerSec=2.250395251961201, CurrSamplesPerSec=2.0982912902060784, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 13:56:12,123] [INFO] [logging.py:96:log_dist] [Rank 0] step=2890, skipped=0, lr=[3.0388059701492537e-05], mom=[[0.9, 0.98]]
[2025-04-12 13:56:12,124] [INFO] [timer.py:260:stop] epoch=0/micro_step=92480/global_step=2890, RunningAvgSamplesPerSec=2.2502470451824674, CurrSamplesPerSec=2.1306792365428944, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=8][batch=86/402]:
	 Train time/batch: 2899
	 Train time/sample: 185123
	 Train time/batch_in_epoch: 85
	 Train time/sample_in_epoch: 5440
	 Train time/token: 188899073
	 Train time/token_in_epoch: 5551040
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0354
	 Train memory/reserved_mem: 33.1960
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.3211
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 10.5460
	 Train throughput/batches_per_sec: 0.0330
	 Train throughput/samples_per_sec: 2.1101
	 Train throughput/device/batches_per_sec: 0.0330
	 Train throughput/device/samples_per_sec: 2.1101
	 Train time/train: 24.0140
	 Train time/val: 3.1211
	 Train time/total: 27.1352
[2025-04-12 14:01:25,415] [INFO] [logging.py:96:log_dist] [Rank 0] step=2900, skipped=0, lr=[3.0189054726368164e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:01:25,416] [INFO] [timer.py:260:stop] epoch=0/micro_step=92800/global_step=2900, RunningAvgSamplesPerSec=2.249858379759918, CurrSamplesPerSec=2.26823015861783, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 14:06:39,441] [INFO] [logging.py:96:log_dist] [Rank 0] step=2910, skipped=0, lr=[2.999004975124378e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:06:39,442] [INFO] [timer.py:260:stop] epoch=0/micro_step=93120/global_step=2910, RunningAvgSamplesPerSec=2.2494432145576955, CurrSamplesPerSec=2.289662552155978, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 14:11:46,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=2920, skipped=0, lr=[2.979104477611941e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:11:46,018] [INFO] [timer.py:260:stop] epoch=0/micro_step=93440/global_step=2920, RunningAvgSamplesPerSec=2.249197276719625, CurrSamplesPerSec=2.092357477266643, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 14:17:01,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=2930, skipped=0, lr=[2.9592039800995027e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:17:01,537] [INFO] [timer.py:260:stop] epoch=0/micro_step=93760/global_step=2930, RunningAvgSamplesPerSec=2.2487730934533583, CurrSamplesPerSec=2.036864363441757, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 14:22:06,731] [INFO] [logging.py:96:log_dist] [Rank 0] step=2940, skipped=0, lr=[2.9393034825870653e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:22:06,732] [INFO] [timer.py:260:stop] epoch=0/micro_step=94080/global_step=2940, RunningAvgSamplesPerSec=2.248605410785502, CurrSamplesPerSec=2.1187854784080193, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=8][batch=136/402]:
	 Train time/batch: 2949
	 Train time/sample: 188323
	 Train time/batch_in_epoch: 135
	 Train time/sample_in_epoch: 8640
	 Train time/token: 192165057
	 Train time/token_in_epoch: 8817024
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0376
	 Train memory/reserved_mem: 33.1960
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.3338
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 10.1381
	 Train throughput/batches_per_sec: 0.0332
	 Train throughput/samples_per_sec: 2.1220
	 Train throughput/device/batches_per_sec: 0.0332
	 Train throughput/device/samples_per_sec: 2.1220
	 Train time/train: 24.4450
	 Train time/val: 3.1211
	 Train time/total: 27.5661
[2025-04-12 14:27:17,967] [INFO] [logging.py:96:log_dist] [Rank 0] step=2950, skipped=0, lr=[2.9194029850746273e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:27:17,968] [INFO] [timer.py:260:stop] epoch=0/micro_step=94400/global_step=2950, RunningAvgSamplesPerSec=2.2482814768650146, CurrSamplesPerSec=2.045203573580606, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 14:32:23,024] [INFO] [logging.py:96:log_dist] [Rank 0] step=2960, skipped=0, lr=[2.899502487562189e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:32:23,025] [INFO] [timer.py:260:stop] epoch=0/micro_step=94720/global_step=2960, RunningAvgSamplesPerSec=2.248094501031174, CurrSamplesPerSec=2.2963516817938388, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 14:37:31,543] [INFO] [logging.py:96:log_dist] [Rank 0] step=2970, skipped=0, lr=[2.879601990049751e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:37:31,544] [INFO] [timer.py:260:stop] epoch=0/micro_step=95040/global_step=2970, RunningAvgSamplesPerSec=2.2478215150619185, CurrSamplesPerSec=2.1450419896040733, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 14:42:45,707] [INFO] [logging.py:96:log_dist] [Rank 0] step=2980, skipped=0, lr=[2.8597014925373136e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:42:45,708] [INFO] [timer.py:260:stop] epoch=0/micro_step=95360/global_step=2980, RunningAvgSamplesPerSec=2.2474122281600115, CurrSamplesPerSec=2.0518837887032086, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 14:48:01,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=2990, skipped=0, lr=[2.8398009950248756e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:48:01,824] [INFO] [timer.py:260:stop] epoch=0/micro_step=95680/global_step=2990, RunningAvgSamplesPerSec=2.2469424328586687, CurrSamplesPerSec=1.991349353047165, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=8][batch=186/402]:
	 Train time/batch: 2999
	 Train time/sample: 191523
	 Train time/batch_in_epoch: 185
	 Train time/sample_in_epoch: 11840
	 Train time/token: 195430529
	 Train time/token_in_epoch: 12082496
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0376
	 Train memory/reserved_mem: 33.1960
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.2886
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 9.7301
	 Train throughput/batches_per_sec: 0.0316
	 Train throughput/samples_per_sec: 2.0203
	 Train throughput/device/batches_per_sec: 0.0316
	 Train throughput/device/samples_per_sec: 2.0203
	 Train time/train: 24.8781
	 Train time/val: 3.1211
	 Train time/total: 27.9992
[2025-04-12 14:53:10,541] [INFO] [logging.py:96:log_dist] [Rank 0] step=3000, skipped=0, lr=[2.8199004975124383e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:53:10,542] [INFO] [timer.py:260:stop] epoch=0/micro_step=96000/global_step=3000, RunningAvgSamplesPerSec=2.246694372973483, CurrSamplesPerSec=2.159679756968677, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 14:58:23,681] [INFO] [logging.py:96:log_dist] [Rank 0] step=3010, skipped=0, lr=[2.8e-05], mom=[[0.9, 0.98]]
[2025-04-12 14:58:23,682] [INFO] [timer.py:260:stop] epoch=0/micro_step=96320/global_step=3010, RunningAvgSamplesPerSec=2.246308290124277, CurrSamplesPerSec=2.0405756840888465, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 15:03:36,372] [INFO] [logging.py:96:log_dist] [Rank 0] step=3020, skipped=0, lr=[2.7800995024875626e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:03:36,373] [INFO] [timer.py:260:stop] epoch=0/micro_step=96640/global_step=3020, RunningAvgSamplesPerSec=2.245914952101931, CurrSamplesPerSec=2.061097083792332, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 15:08:45,307] [INFO] [logging.py:96:log_dist] [Rank 0] step=3030, skipped=0, lr=[2.7601990049751246e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:08:45,308] [INFO] [timer.py:260:stop] epoch=0/micro_step=96960/global_step=3030, RunningAvgSamplesPerSec=2.245596021713607, CurrSamplesPerSec=2.2562351762381567, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 15:13:53,465] [INFO] [logging.py:96:log_dist] [Rank 0] step=3040, skipped=0, lr=[2.7402985074626873e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:13:53,466] [INFO] [timer.py:260:stop] epoch=0/micro_step=97280/global_step=3040, RunningAvgSamplesPerSec=2.2453068483727123, CurrSamplesPerSec=2.338100998004698, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=8][batch=236/402]:
	 Train time/batch: 3049
	 Train time/sample: 194723
	 Train time/batch_in_epoch: 235
	 Train time/sample_in_epoch: 15040
	 Train time/token: 198698369
	 Train time/token_in_epoch: 15350336
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0397
	 Train memory/reserved_mem: 33.1960
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.2503
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 9.3207
	 Train throughput/batches_per_sec: 0.0321
	 Train throughput/samples_per_sec: 2.0528
	 Train throughput/device/batches_per_sec: 0.0321
	 Train throughput/device/samples_per_sec: 2.0528
	 Train time/train: 25.3091
	 Train time/val: 3.1211
	 Train time/total: 28.4303
[2025-04-12 15:19:07,587] [INFO] [logging.py:96:log_dist] [Rank 0] step=3050, skipped=0, lr=[2.7203980099502483e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:19:07,588] [INFO] [timer.py:260:stop] epoch=0/micro_step=97600/global_step=3050, RunningAvgSamplesPerSec=2.244870851481849, CurrSamplesPerSec=2.161362830772353, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 15:24:14,559] [INFO] [logging.py:96:log_dist] [Rank 0] step=3060, skipped=0, lr=[2.700497512437811e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:24:14,560] [INFO] [timer.py:260:stop] epoch=0/micro_step=97920/global_step=3060, RunningAvgSamplesPerSec=2.244620644562033, CurrSamplesPerSec=2.097636160646329, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 15:29:13,318] [INFO] [logging.py:96:log_dist] [Rank 0] step=3070, skipped=0, lr=[2.680597014925373e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:29:13,320] [INFO] [timer.py:260:stop] epoch=0/micro_step=98240/global_step=3070, RunningAvgSamplesPerSec=2.244593587625202, CurrSamplesPerSec=2.212158563524975, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 15:34:21,731] [INFO] [logging.py:96:log_dist] [Rank 0] step=3080, skipped=0, lr=[2.6606965174129356e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:34:21,732] [INFO] [timer.py:260:stop] epoch=0/micro_step=98560/global_step=3080, RunningAvgSamplesPerSec=2.244295283982291, CurrSamplesPerSec=2.0089451360473807, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 15:39:27,810] [INFO] [logging.py:96:log_dist] [Rank 0] step=3090, skipped=0, lr=[2.6407960199004972e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:39:27,812] [INFO] [timer.py:260:stop] epoch=0/micro_step=98880/global_step=3090, RunningAvgSamplesPerSec=2.244060647244898, CurrSamplesPerSec=2.2792723224365306, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=8][batch=286/402]:
	 Train time/batch: 3099
	 Train time/sample: 197923
	 Train time/batch_in_epoch: 285
	 Train time/sample_in_epoch: 18240
	 Train time/token: 201963137
	 Train time/token_in_epoch: 18615104
	 Train memory/allocated_mem: 3.3472
	 Train memory/active_mem: 3.3472
	 Train memory/inactive_mem: 0.0355
	 Train memory/reserved_mem: 33.1960
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.2683
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 8.9090
	 Train throughput/batches_per_sec: 0.0329
	 Train throughput/samples_per_sec: 2.1055
	 Train throughput/device/batches_per_sec: 0.0329
	 Train throughput/device/samples_per_sec: 2.1055
	 Train time/train: 25.7349
	 Train time/val: 3.1211
	 Train time/total: 28.8560
[2025-04-12 15:44:38,077] [INFO] [logging.py:96:log_dist] [Rank 0] step=3100, skipped=0, lr=[2.6208955223880603e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:44:38,079] [INFO] [timer.py:260:stop] epoch=0/micro_step=99200/global_step=3100, RunningAvgSamplesPerSec=2.24372320666686, CurrSamplesPerSec=2.026775070012092, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 15:49:41,569] [INFO] [logging.py:96:log_dist] [Rank 0] step=3110, skipped=0, lr=[2.600995024875622e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:49:41,570] [INFO] [timer.py:260:stop] epoch=0/micro_step=99520/global_step=3110, RunningAvgSamplesPerSec=2.243556112829165, CurrSamplesPerSec=2.21938051530334, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 15:55:01,676] [INFO] [logging.py:96:log_dist] [Rank 0] step=3120, skipped=0, lr=[2.5810945273631846e-05], mom=[[0.9, 0.98]]
[2025-04-12 15:55:01,677] [INFO] [timer.py:260:stop] epoch=0/micro_step=99840/global_step=3120, RunningAvgSamplesPerSec=2.2430184997853546, CurrSamplesPerSec=1.966810918028126, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 16:00:05,344] [INFO] [logging.py:96:log_dist] [Rank 0] step=3130, skipped=0, lr=[2.5611940298507466e-05], mom=[[0.9, 0.98]]
[2025-04-12 16:00:05,345] [INFO] [timer.py:260:stop] epoch=0/micro_step=100160/global_step=3130, RunningAvgSamplesPerSec=2.2428651639602792, CurrSamplesPerSec=2.163545899298226, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 16:05:10,619] [INFO] [logging.py:96:log_dist] [Rank 0] step=3140, skipped=0, lr=[2.5412935323383082e-05], mom=[[0.9, 0.98]]
[2025-04-12 16:05:10,620] [INFO] [timer.py:260:stop] epoch=0/micro_step=100480/global_step=3140, RunningAvgSamplesPerSec=2.242655734211838, CurrSamplesPerSec=2.254021242301443, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=8][batch=336/402]:
	 Train time/batch: 3149
	 Train time/sample: 201123
	 Train time/batch_in_epoch: 335
	 Train time/sample_in_epoch: 21440
	 Train time/token: 205231105
	 Train time/token_in_epoch: 21883072
	 Train memory/allocated_mem: 3.3473
	 Train memory/active_mem: 3.3473
	 Train memory/inactive_mem: 0.0375
	 Train memory/reserved_mem: 33.1960
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.3076
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 8.4979
	 Train throughput/batches_per_sec: 0.0320
	 Train throughput/samples_per_sec: 2.0491
	 Train throughput/device/batches_per_sec: 0.0320
	 Train throughput/device/samples_per_sec: 2.0491
	 Train time/train: 26.1642
	 Train time/val: 3.1211
	 Train time/total: 29.2854
[2025-04-12 16:10:21,342] [INFO] [logging.py:96:log_dist] [Rank 0] step=3150, skipped=0, lr=[2.5213930348258702e-05], mom=[[0.9, 0.98]]
[2025-04-12 16:10:21,343] [INFO] [timer.py:260:stop] epoch=0/micro_step=100800/global_step=3150, RunningAvgSamplesPerSec=2.242330327513034, CurrSamplesPerSec=2.3136655048095216, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 16:15:25,707] [INFO] [logging.py:96:log_dist] [Rank 0] step=3160, skipped=0, lr=[2.501492537313433e-05], mom=[[0.9, 0.98]]
[2025-04-12 16:15:25,708] [INFO] [timer.py:260:stop] epoch=0/micro_step=101120/global_step=3160, RunningAvgSamplesPerSec=2.2421673265925075, CurrSamplesPerSec=2.152257768965056, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 16:20:28,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=3170, skipped=0, lr=[2.481592039800995e-05], mom=[[0.9, 0.98]]
[2025-04-12 16:20:28,734] [INFO] [timer.py:260:stop] epoch=0/micro_step=101440/global_step=3170, RunningAvgSamplesPerSec=2.2420357056709435, CurrSamplesPerSec=2.3887714238443505, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 16:25:32,063] [INFO] [logging.py:96:log_dist] [Rank 0] step=3180, skipped=0, lr=[2.4616915422885575e-05], mom=[[0.9, 0.98]]
[2025-04-12 16:25:32,064] [INFO] [timer.py:260:stop] epoch=0/micro_step=101760/global_step=3180, RunningAvgSamplesPerSec=2.241887402302173, CurrSamplesPerSec=2.1749134123664637, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[2025-04-12 16:30:37,845] [INFO] [logging.py:96:log_dist] [Rank 0] step=3190, skipped=0, lr=[2.4417910447761192e-05], mom=[[0.9, 0.98]]
[2025-04-12 16:30:37,847] [INFO] [timer.py:260:stop] epoch=0/micro_step=102080/global_step=3190, RunningAvgSamplesPerSec=2.241687788582439, CurrSamplesPerSec=2.261952009487753, MemAllocated=3.62GB, MaxMemAllocated=17.36GB
[epoch=8][batch=386/402]:
	 Train time/batch: 3199
	 Train time/sample: 204323
	 Train time/batch_in_epoch: 385
	 Train time/sample_in_epoch: 24640
	 Train time/token: 208495425
	 Train time/token_in_epoch: 25147392
	 Train memory/allocated_mem: 3.3467
	 Train memory/active_mem: 3.3467
	 Train memory/inactive_mem: 0.0402
	 Train memory/reserved_mem: 33.3200
	 Train memory/alloc_retries: 0
	 Train trainer/device_train_microbatch_size: 2
	 Train loss/train/total: 0.2479
	 Train lr-DeepSpeedZeroOptimizer_Stage3/group0: 0.0000
	 Train time/remaining_estimate: 8.0847
	 Train throughput/batches_per_sec: 0.0324
	 Train throughput/samples_per_sec: 2.0712
	 Train throughput/device/batches_per_sec: 0.0324
	 Train throughput/device/samples_per_sec: 2.0712
	 Train time/train: 26.5879
	 Train time/val: 3.1211
	 Train time/total: 29.7090
[2025-04-12 16:35:44,486] [INFO] [logging.py:96:log_dist] [Rank 0] step=3200, skipped=0, lr=[2.421890547263682e-05], mom=[[0.9, 0.98]]
